syntax = "proto2";

//option optimize_for = LITE_RUNTIME;

package caffe;

// Specifies the shape (dimensions) of a Blob.
message BlobShape {
  repeated int64 dim = 1 [packed = true];
}

message BlobProto {
  optional BlobShape shape = 7;
  repeated float data = 5 [packed = true];
  repeated float diff = 6 [packed = true];

  // 5D dimensions -- deprecated.  Use "shape" instead.
  optional int32 num = 1 [default = 0];
  optional int32 channels = 2 [default = 0];
  optional int32 height = 3 [default = 0];
  optional int32 width = 4 [default = 0];
  optional int32 depth = 8 [default = 0];


}

// The BlobProtoVector is simply a way to pass multiple blobproto instances
// around.
message BlobProtoVector {
  repeated BlobProto blobs = 1;
}

message QuantizeParameter {
    optional string type       = 1 [default = "quantize"];
    optional float  step       = 2 [default = 0.1];       // each one in uint8_t represents how much in float.
    optional float  range_min  = 3 [default = 0];  // what 0 represents.
    optional float  range_max  = 4 [default = 255];  // what 255 represents.
    optional uint32 zero_point = 5 [default = 0]; // what 0.0f is represented in uint8
    optional bool	adjust_range = 6 [default = false]; // whether to adjust range_min and range_max such that zero_point can be precisely represented by integer.
}

message Datum {
  optional int32 channels = 1;
  optional int32 height = 2;
  optional int32 width = 3;
  // the actual image data, in bytes
  optional bytes data = 4;
  optional int32 label = 5;
  // Optionally, the datum could also hold float data.
  repeated float float_data = 6;
  // If true data contains an encoded image that need to be decoded
  optional bool encoded = 7 [default = false];
  optional int32 depth = 8;
}

message FillerParameter {
  // The filler type.
  optional string type = 1 [default = 'constant'];
  optional float value = 2 [default = 0]; // the value in constant filler
  optional float min = 3 [default = 0]; // the min value in uniform filler
  optional float max = 4 [default = 1]; // the max value in uniform filler
  optional float mean = 5 [default = 0]; // the mean value in Gaussian filler
  optional float std = 6 [default = 1]; // the std value in Gaussian filler
  // The expected number of non-zero output weights for a given input in
  // Gaussian filler -- the default -1 means don't perform sparsification.
  optional int32 sparse = 7 [default = -1];
}

message NetParameter {
  optional string name = 1; // consider giving the network a name
  // The input blobs to the network.
  repeated string input = 3;
  // The shape of the input blobs.
  repeated BlobShape input_shape = 8;

  // 4D input dimensions -- deprecated.  Use "shape" instead.
  // If specified, for each input blob there should be four
  // values specifying the num, channels, height and width of the input blob.
  // Thus, there should be a total of (4 * #input) numbers.
  repeated int32 input_dim = 4;

  // Whether the network will force every layer to carry out backward operation.
  // If set False, then whether to carry out backward is determined
  // automatically according to the net structure and learning rates.
  optional bool force_backward = 5 [default = false];
  // The current "state" of the network, including the phase, level, and stage.
  // Some layers may be included/excluded depending on this state and the states
  // specified in the layers' include and exclude fields.
  optional NetState state = 6;

  // Print debugging information about results while running Net::Forward,
  // Net::Backward, and Net::Update.
  optional bool debug_info = 7 [default = false];

  // The layers that make up the net.  Each of their configurations, including
  // connectivity and behavior, is specified as a LayerParameter.
  repeated LayerParameter layer = 100;  // ID 100 so layers are printed last.

  // DEPRECATED: use 'layer' instead.
  repeated V1LayerParameter layers = 2;
}

// NOTE
// Update the next available ID when you add a new SolverParameter field.
//
// SolverParameter next available ID: 36 (last added: clip_gradients)
message SolverParameter {
  //////////////////////////////////////////////////////////////////////////////
  // Specifying the train and test networks
  //
  // Exactly one train net must be specified using one of the following fields:
  //     train_net_param, train_net, net_param, net
  // One or more test nets may be specified using any of the following fields:
  //     test_net_param, test_net, net_param, net
  // If more than one test net field is specified (e.g., both net and
  // test_net are specified), they will be evaluated in the field order given
  // above: (1) test_net_param, (2) test_net, (3) net_param/net.
  // A test_iter must be specified for each test_net.
  // A test_level and/or a test_stage may also be specified for each test_net.
  //////////////////////////////////////////////////////////////////////////////

  // Proto filename for the train net, possibly combined with one or more
  // test nets.
  optional string net = 24;
  // Inline train net param, possibly combined with one or more test nets.
  optional NetParameter net_param = 25;

  optional string train_net = 1; // Proto filename for the train net.
  repeated string test_net = 2; // Proto filenames for the test nets.
  optional NetParameter train_net_param = 21; // Inline train net params.
  repeated NetParameter test_net_param = 22; // Inline test net params.

  // The states for the train/test nets. Must be unspecified or
  // specified once per net.
  //
  // By default, all states will have solver = true;
  // train_state will have phase = TRAIN,
  // and all test_state's will have phase = TEST.
  // Other defaults are set according to the NetState defaults.
  optional NetState train_state = 26;
  repeated NetState test_state = 27;

  // The number of iterations for each test net.
  repeated int32 test_iter = 3;

  // The number of iterations between two testing phases.
  optional int32 test_interval = 4 [default = 0];
  optional bool test_compute_loss = 19 [default = false];
  // If true, run an initial test pass before the first iteration,
  // ensuring memory availability and printing the starting value of the loss.
  optional bool test_initialization = 32 [default = true];
  optional float base_lr = 5; // The base learning rate
  // the number of iterations between displaying info. If display = 0, no info
  // will be displayed.
  optional int32 display = 6;
  // Display the loss averaged over the last average_loss iterations
  optional int32 average_loss = 33 [default = 1];
  optional int32 max_iter = 7; // the maximum number of iterations
  optional string lr_policy = 8; // The learning rate decay policy.
  optional float gamma = 9; // The parameter to compute the learning rate.
  optional float power = 10; // The parameter to compute the learning rate.
  optional float momentum = 11; // The momentum value.
  optional float weight_decay = 12; // The weight decay.
  // regularization types supported: L1 and L2
  // controlled by weight_decay
  optional string regularization_type = 29 [default = "L2"];
  // the stepsize for learning rate policy "step"
  optional int32 stepsize = 13;
  // the stepsize for learning rate policy "multistep"
  repeated int32 stepvalue = 34;

  // Set clip_gradients to >= 0 to clip parameter gradients to that L2 norm,
  // whenever their actual L2 norm is larger.
  optional float clip_gradients = 35 [default = -1];

  optional int32 snapshot = 14 [default = 0]; // The snapshot interval
  optional string snapshot_prefix = 15; // The prefix for the snapshot.
  // whether to snapshot diff in the results or not. Snapshotting diff will help
  // debugging but the final protocol buffer size will be much larger.
  optional bool snapshot_diff = 16 [default = false];
  // the mode solver will use: 0 for CPU and 1 for GPU. Use GPU in default.
  enum SolverMode {
    CPU = 0;
    GPU = 1;
  }
  optional SolverMode solver_mode = 17 [default = GPU];
  // the device_id will that be used in GPU mode. Use device_id = 0 in default.
  optional int32 device_id = 18 [default = 0];
  // If non-negative, the seed with which the Solver will initialize the Caffe
  // random number generator -- useful for reproducible results. Otherwise,
  // (and by default) initialize using a seed derived from the system clock.
  optional int64 random_seed = 20 [default = -1];

  // Solver type
  enum SolverType {
    SGD = 0;
    NESTEROV = 1;
    ADAGRAD = 2;
  }
  optional SolverType solver_type = 30 [default = SGD];
  // numerical stability for AdaGrad
  optional float delta = 31 [default = 1e-8];

  // If true, print information about the state of the net that may help with
  // debugging learning problems.
  optional bool debug_info = 23 [default = false];

  // If false, don't save a snapshot after training finishes.
  optional bool snapshot_after_train = 28 [default = true];
}

// A message that stores the solver snapshots
message SolverState {
  optional int32 iter = 1; // The current iteration
  optional string learned_net = 2; // The file that stores the learned net.
  repeated BlobProto history = 3; // The history for sgd solvers
  optional int32 current_step = 4 [default = 0]; // The current step for learning rate
}

enum Phase {
   TRAIN = 0;
   TEST = 1;
}

message NetState {
  optional Phase phase = 1 [default = TEST];
  optional int32 level = 2 [default = 0];
  repeated string stage = 3;
}

message NetStateRule {
  // Set phase to require the NetState have a particular phase (TRAIN or TEST)
  // to meet this rule.
  optional Phase phase = 1;

  // Set the minimum and/or maximum levels in which the layer should be used.
  // Leave undefined to meet the rule regardless of level.
  optional int32 min_level = 2;
  optional int32 max_level = 3;

  // Customizable sets of stages to include or exclude.
  // The net must have ALL of the specified stages and NONE of the specified
  // "not_stage"s to meet the rule.
  // (Use multiple NetStateRules to specify conjunctions of stages.)
  repeated string stage = 4;
  repeated string not_stage = 5;
}

// Specifies training parameters (multipliers on global learning constants,
// and the name and other settings used for weight sharing).
message ParamSpec {
  // The names of the parameter blobs -- useful for sharing parameters among
  // layers, but never required otherwise.  To share a parameter between two
  // layers, give it a (non-empty) name.
  optional string name = 1;

  // Whether to require shared weights to have the same shape, or just the same
  // count -- defaults to STRICT if unspecified.
  optional DimCheckMode share_mode = 2;
  enum DimCheckMode {
    // STRICT (default) requires that num, channels, height, width each match.
    STRICT = 0;
    // PERMISSIVE requires only the count (num*channels*height*width) to match.
    PERMISSIVE = 1;
  }

  // The multiplier on the global learning rate for this parameter.
  optional float lr_mult = 3 [default = 1.0];

  // The multiplier on the global weight decay for this parameter.
  optional float decay_mult = 4 [default = 1.0];
}

// NOTE
// Update the next available ID when you add a new LayerParameter field.
//
// LayerParameter next available layer-specific ID: 143 (last added: detection_output_param)
message LayerParameter {
  optional string name = 1; // the layer name
  optional string type = 2; // the layer type
  repeated string bottom = 3; // the name of each bottom blob
  repeated string top = 4; // the name of each top blob

  // The train / test phase for computation.
  optional Phase phase = 10;

  // The amount of weight to assign each top blob in the objective.
  // Each layer assigns a default value, usually of either 0 or 1,
  // to each top blob.
  repeated float loss_weight = 5;

  // Specifies training parameters (multipliers on global learning constants,
  // and the name and other settings used for weight sharing).
  repeated ParamSpec param = 6;

  // The blobs containing the numeric parameters of the layer.
  repeated BlobProto blobs = 7;

  // Rules controlling whether and when a layer is included in the network,
  // based on the current NetState.  You may specify a non-zero number of rules
  // to include OR exclude, but not both.  If no include or exclude rules are
  // specified, the layer is always included.  If the current NetState meets
  // ANY (i.e., one or more) of the specified rules, the layer is
  // included/excluded.
  repeated NetStateRule include = 8;
  repeated NetStateRule exclude = 9;

  // set data type of top blobs;(fp32 fp16 uchar int8 ...)
  optional string top_data_type = 11 [default='None']; 

  enum PrecisionType {
    DEFAULT = 0;
    INT8 = 1;
    FLOAT16 = 2;
    FLOAT32 = 3;
    INT4B = 4;
    UINT8 = 5;
    UINT16 = 6;
  }
  optional PrecisionType forward_precision = 12 [default = DEFAULT];

  // Parameters for data pre-processing.
  optional TransformationParameter transform_param = 100;

  // Parameters shared by loss layers.
  optional LossParameter loss_param = 101;

  // Layer type-specific parameters.
  //
  // Note: certain layers may have more than one computational engine
  // for their implementation. These layers include an Engine type and
  // engine parameter for selecting the implementation.
  // The default for the engine is set by the ENGINE switch at compile-time.
  optional AccuracyParameter accuracy_param = 102;
  optional ArgMaxParameter argmax_param = 103;
  optional ConcatParameter concat_param = 104;
  optional ContrastiveLossParameter contrastive_loss_param = 105;
  optional ConvolutionParameter convolution_param = 106;
  optional DataParameter data_param = 107;
  optional DropoutParameter dropout_param = 108;
  optional DummyDataParameter dummy_data_param = 109;
  optional EltwiseParameter eltwise_param = 110;
  optional ExpParameter exp_param = 111;
  optional HDF5DataParameter hdf5_data_param = 112;
  optional HDF5OutputParameter hdf5_output_param = 113;
  optional HingeLossParameter hinge_loss_param = 114;
  optional ImageDataParameter image_data_param = 115;
  optional InfogainLossParameter infogain_loss_param = 116;
  optional InnerProductParameter inner_product_param = 117;
  optional LRNParameter lrn_param = 118;
  optional MemoryDataParameter memory_data_param = 119;
  optional MVNParameter mvn_param = 120;
  optional PoolingParameter pooling_param = 121;
  optional PoolingSpecificParameter pooling_specific_param = 1210;
  optional PowerParameter power_param = 122;
  optional ReLUParameter relu_param = 123;
  optional SigmoidParameter sigmoid_param = 124;
  optional SoftmaxParameter softmax_param = 125;
  optional SliceParameter slice_param = 126;
  optional TanHParameter tanh_param = 127;
  optional ThresholdParameter threshold_param = 128;
  optional WindowDataParameter window_data_param = 129;
  optional PythonParameter python_param = 130;
  optional CTCParameter ctc_param = 131;
  optional PReLUParameter prelu_param = 132;
  optional ReshapeParameter reshape_param = 133;
  optional ROIPoolingParameter roi_pooling_param = 134;
  optional AffineTransParameter affine_trans_param = 135;
  optional ROIParameter roi_param = 136;
  optional AffineTransPointParameter affine_trans_point_param = 137;
  optional PermuteParameter permute_param = 138;
  optional PriorBoxParameter prior_box_param = 139;
  optional CalcAffineMatParameter calc_affine_mat_param = 140;
  optional InterpParameter interp_param = 141;
  optional DetectionOutputParameter detection_output_param = 142;
  optional ReLU6Parameter relu6_param = 143;


  //! add by linan 2017.11.23
  //! original number is 141
  optional BiasParameter bias_param = 144;
  //! <<<

  //! add by linan 2017.4.20
  optional ZXYBNParameter zxybn_param = 145;
  //! add by linan 2016.12.26
  optional CorrelationParameter correlation_param = 150;

  //! add by pengcuo 2017.02.07
  optional PSROIPoolingParameter psroi_pooling_param = 152;
  optional NNUpsampleParameter nn_upsample_param = 163;

  //! add by linan 2017.5.3
  optional ROIAlignParameter roi_align_param = 153;

  optional RpnProposalLayerParameter rpn_proposal_param = 166;
  optional ROIMaskPoolingParameter roi_mask_pooling_param = 176;

  //! add by pengcuo 2017.09.07
  optional ChannelShuffleParameter channel_shuffle_param = 177;

  optional BNParameter bn_param = 178;

  //! add pengcuo 2017.8.17
  optional ROIAlignPoolingPodParameter roi_align_pooling_pod_param = 205;
  optional ROIAlignPoolingParameter roi_align_pooling_param = 206;
  optional PSROIAlignPoolingParameter psroi_align_pooling_param = 207;

  //! add by pengcuo 2017.09.21
  optional AlignmentToROIParameter alignment_to_roi_param = 218;

  //! add by pengcuo 2017.08
  optional UnpoolingParameter unpooling_param = 243;

  optional LogParameter log_param = 244;

  //! add by linan 2017.10.17
  optional ReverseParameter reverse_param = 301;
  optional LSTMParameter lstm_param = 302;
  optional PriorVBoxParameter prior_vbox_param = 304;
  //! <<<

  optional BTCostVolumeParameter btcostvolume_param = 1001;


  //! add by yingrui 2017.12.22
  optional MovingAvgParameter moving_avg_param = 1799;

  //! add by yingrui 2017.10.25
  optional SlicingParameter slicing_param = 5180;
  optional BilateralSlicingParameter bilateral_slicing_param = 5181;
  optional BilateralSliceApplyParameter bilateral_slice_apply_param = 5182;
  optional AdaptiveBilateralSliceApplyParameter adaptive_bilateral_slice_apply_param = 5183;

  //! add by yingrui 2017.11.07
  optional PointsCurveParameter pointscurve_param = 2000;
  optional SubpixelDownParameter subpixel_down_param = 2001;
  optional SubpixelUpParameter subpixel_up_param = 2002;
  optional ClipParameter clip_param = 2003;
  optional EltwiseAffineTransformParameter eltwise_affine_transform_param = 2004;
  optional TileParameter tile_param = 2005;
  optional PadParameter  pad_param = 2006;
  optional ReduceParameter reduce_param = 2007;

  //! add by linan 2019.11.15, 3d layer parameters
  optional Convolution3dParameter convolution3d_param = 2008;
  //optional ConvolutionTranspose3dParameter convolution_transpose3d_param = 2009;
  optional Deconvolution3dParameter deconvolution3d_param = 2009;
  optional ReLU3dParameter relu3d_param = 2010;
  optional PReLUParameter prelu3d_param = 2011;
  optional ReLU3dParameter leaky_relu3d_param = 2012;
  optional ReLU3dParameter elu3d_param = 2013;
  optional GroupNorm3dParameter groupnorm3d_param = 2014;
  optional BatchNorm3dParameter batchnorm3d_param = 2015;
  optional Pooling3dParameter maxpooling3d_param = 2016;
  optional Pooling3dParameter avepooling3d_param = 2017;
  optional DropoutParameter dropout3d_param = 2018;
  optional Interp3dParameter interp3d_param = 2019;
  optional Pooling3dParameter pooling3d_param = 2020;
  optional ReshapeParameter reshape3d_param = 2022;
  optional SoftmaxParameter softmax3d_param = 2023;
  optional ArgMaxParameter argmax3d_param = 2024;
  optional InnerProductParameter inner_product3d_param = 2025;
  optional SliceParameter slice3d_param = 2026;
  optional ConcatParameter concat3d_param = 2027;
  optional BNParameter bn3d_param = 2028;
  optional MatMulParameter matmul3d_param = 2029;
  optional TransposeParameter transpose3d_param = 2030;


  optional ScaleParameter scale_param = 5001;
  optional CropParameter crop_param = 5002;
  optional RecurrentParameter recurrent_param = 5004;
  optional BatchNormParameter batch_norm_param = 5005;
  optional FlattenParameter flatten_param = 5006;
  optional ScalesParameter scales_param = 5007;
  optional TransposeParameter transpose_param = 5008;

  //! add by linan 2018.5.28
  optional HeatMap2CoordParameter heatmap_param = 5009;
  optional NormalizeParameter normalize_param = 5010;

  optional Correlation2DParameter correlation2d_param = 5011;

  //! add by linjin 2020.02.19
  optional MatMulParameter matmul_param = 5012;
  optional ParameterParameter parameter_param = 5013;

  //! add by liangjiexin 2020.3.2
  optional PixelShuffleParameter pixelshuffle_param = 5014;

  //! add by liangjiexin 2020.4.15
  optional ROITransformParameter roi_transform_param = 5015;

  //! add by linjin 2020.4.27
  optional InstanceNormParameter instance_norm_param = 5016;

  //! add by jianfei 2020.8.14
  optional GridSampleParameter grid_sample_param = 5018;
  //! add by jianfei 2020.7.14
  optional ReduceL2Parameter reducel2_param = 5017;

  //! add by linjin 2020.8.19
  optional MeanParameter mean_param = 5019;
  //! add by linjin 2020.8.6
  optional VarianceParameter variance_param = 5020;
  //! add by linjin 2020.9.3
  optional GridSample3DParameter grid_sample_3d_param = 5021;

  //! add by liangjiexin 2020.9.10
  optional GRUParameter gru_param = 5022;
  //! add by jianfei 2020.9.27
  optional CorrelationMigParameter correlationmig_param = 5023;
  //! add by jianfei 2020.10.15
  optional ArgSortParameter argsort_param = 5024;
  optional CumProdParameter cumprod_param = 5025;

  //! add by liangjiexin 2020.10.28
  optional MainTransformParameter main_transform_param = 5026;

  repeated QuantizeParameter quantize_param = 6000;

  //! added by tianzichen 2020.10.29
  // hexagon dsp uint16 quantize bits, used only when PrecisionType = UINT16, range [1, 16]
  // default = 0 means this layer's quantize bits is not specified, will use global quantize bits.
  optional uint32 quantize_bits = 6001 [default = 0];
  
}

message Convolution3dParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
  optional bool bias_term = 2 [default = true]; // whether to have bias terms
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pad = 3 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 pad_d = 23 [default = 0]; // The padding depth
  optional uint32 pad_h = 9 [default = 0]; // The padding height
  optional uint32 pad_w = 10 [default = 0]; // The padding width
  optional uint32 kernel_size = 4; // The kernel size (square)
  optional uint32 kernel_d = 22; // The kernel depth
  optional uint32 kernel_h = 11; // The kernel height
  optional uint32 kernel_w = 12; // The kernel width
  optional uint32 group = 5 [default = 1]; // The group size for group conv
  optional uint32 stride = 6 [default = 1]; // The stride (equal in Y, X)
  optional uint32 stride_d = 21; // The stride depth
  optional uint32 stride_h = 13; // The stride height
  optional uint32 stride_w = 14; // The stride width
  optional uint32 hole = 17 [default = 1];
  optional uint32 hole_d = 19 [default = 1];
  optional uint32 hole_h = 18 [default = 1];
  optional uint32 hole_w = 20 [default = 1];

}

message ConvolutionTranspose3dParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
  optional bool bias_term = 2 [default = true]; // whether to have bias terms
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pad = 3 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 pad_h = 9 [default = 0]; // The padding height
  optional uint32 pad_w = 10 [default = 0]; // The padding width
  optional uint32 kernel_size = 4; // The kernel size (square)
  optional uint32 kernel_h = 11; // The kernel height
  optional uint32 kernel_w = 12; // The kernel width
  optional uint32 group = 5 [default = 1]; // The group size for group conv
  optional uint32 stride = 6 [default = 1]; // The stride (equal in Y, X)
  optional uint32 stride_h = 13; // The stride height
  optional uint32 stride_w = 14; // The stride width
  optional uint32 hole = 17 [default = 1];
  optional uint32 hole_h = 18 [default = 1];
}

message Deconvolution3dParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
  optional bool bias_term = 2 [default = true]; // whether to have bias terms
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pad = 3 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 pad_d = 23 [default = 0]; // The padding depth
  optional uint32 pad_h = 9 [default = 0]; // The padding height
  optional uint32 pad_w = 10 [default = 0]; // The padding width
  optional uint32 kernel_size = 4; // The kernel size (square)
  optional uint32 kernel_d = 22; // The kernel depth
  optional uint32 kernel_h = 11; // The kernel height
  optional uint32 kernel_w = 12; // The kernel width
  optional uint32 group = 5 [default = 1]; // The group size for group conv
  optional uint32 stride = 6 [default = 1]; // The stride (equal in Y, X)
  optional uint32 stride_d = 21; // The stride depth
  optional uint32 stride_h = 13; // The stride height
  optional uint32 stride_w = 14; // The stride width
  optional uint32 hole = 17 [default = 1];
  optional uint32 hole_d = 19 [default = 1];
  optional uint32 hole_h = 18 [default = 1];
  optional uint32 hole_w = 20 [default = 1];

  optional uint32 out_pad = 24 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 out_pad_d = 25 [default = 0]; // The padding depth
  optional uint32 out_pad_h = 26 [default = 0]; // The padding height
  optional uint32 out_pad_w = 27 [default = 0]; // The padding widt
}

message ReLU3dParameter {
  optional float negative_slope = 1 [default=0.0];
  optional bool channel_shared = 2 [default=false];
}

message GroupNorm3dParameter {
  optional uint32 group = 1 [default=1];
  optional float moving_average_fraction = 4 [default = .1];
  optional bool use_global_stats = 2 [default=false];
  optional float eps = 3 [default=0.000001];
}


message BatchNorm3dParameter {
  // How much does the moving average decay each iteration?
  optional float moving_average_fraction = 3 [default = .1];
  optional bool use_global_stats = 1 [default=false];
  optional float eps = 2 [default=0.000001];
}

// Message that stores parameters used by PoolingLayer
message Pooling3dParameter {
  enum PoolMethod {
    MAX = 0;
    AVE = 1;
  }
  optional PoolMethod pool = 1 [default = MAX]; // The pooling method
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pad = 4 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 pad_d = 11 [default = 0]; // The padding depth
  optional uint32 pad_h = 9 [default = 0]; // The padding height
  optional uint32 pad_w = 10 [default = 0]; // The padding width
  optional uint32 kernel_size = 2; // The kernel size (square)
  optional uint32 kernel_d = 14; // The kernel depth
  optional uint32 kernel_h = 5; // The kernel height
  optional uint32 kernel_w = 6; // The kernel width
  optional uint32 stride = 3 [default = 1]; // The stride (equal in Y, X)
  optional uint32 stride_d = 15; // The stride depth
  optional uint32 stride_h = 7; // The stride height
  optional uint32 stride_w = 8; // The stride width

  // If global_pooling then it will pool over the size of the bottom by doing
  // kernel_h = bottom->height and kernel_w = bottom->width
  optional bool global_pooling = 12 [default = false];
  optional bool ceil_mode = 13 [default = true];
}


//use DropoutParameter
//message Dropout3dParameter {
//}
//message DropoutParameter {
//  optional float dropout_ratio = 1 [default = 0.5]; // dropout ratio
//}

// Message that stores parameters used by Interp3dLayer
//message Interp3dParameter {
//  optional int32 depth = 8 [default = 0]; // Depth of output
//  optional int32 height = 1 [default = 0]; // Height of output
//  optional int32 width = 2 [default = 0]; // Width of output
//  optional int32 zoom_factor = 3 [default = 1]; // zoom factor
//  optional int32 shrink_factor = 4 [default = 1]; // shrink factor
//  optional int32 pad_beg = 5 [default = 0]; // padding at begin of input
//  optional int32 pad_end = 6 [default = 0]; // padding at end of input
//  optional bool  align_corners = 7 [default = true];
//}


message NormalizeParameter {
    enum NormalizeMethod{
        L1 = 1;
        L2 = 2;
    }
    optional float coeff = 1 [default = 0];
    optional NormalizeMethod mode = 2 [default = L2];
}

message HeatMap2CoordParameter {
    optional int32 coord_h = 1 [default = 0];
    optional int32 coord_w = 2 [default = 0];
    optional bool coord_reposition = 3 [default = false];
}

message BiasParameter {
  // The first axis of bottom[0] (the first input Blob) along which to apply
  // bottom[1] (the second input Blob).  May be negative to index from the end
  // (e.g., -1 for the last axis).
  //
  // For example, if bottom[0] is 4D with shape 100x3x40x60, the output
  // top[0] will have the same shape, and bottom[1] may have any of the
  // following shapes (for the given value of axis):
  //    (axis == 0 == -4) 100; 100x3; 100x3x40; 100x3x40x60
  //    (axis == 1 == -3)          3;     3x40;     3x40x60
  //    (axis == 2 == -2)                   40;       40x60
  //    (axis == 3 == -1)                                60
  // Furthermore, bottom[1] may have the empty shape (regardless of the value of
  // "axis") -- a scalar bias.
  optional int32 axis = 1 [default = 1];

  // (num_axes is ignored unless just one bottom is given and the bias is
  // a learned parameter of the layer.  Otherwise, num_axes is determined by the
  // number of axes by the second bottom.)
  // The number of axes of the input (bottom[0]) covered by the bias
  // parameter, or -1 to cover all axes of bottom[0] starting from `axis`.
  // Set num_axes := 0, to add a zero-axis Blob: a scalar.
  optional int32 num_axes = 2 [default = 1];

  // (filler is ignored unless just one bottom is given and the bias is
  // a learned parameter of the layer.)
  // The initialization for the learned bias parameter.
  // Default is the zero (0) initialization, resulting in the BiasLayer
  // initially performing the identity operation.
  optional FillerParameter filler = 3;
}

message AlignmentToROIParameter {
    optional float mouth_scale = 1 [default = 1];
    optional float eye_scale = 2 [default = 1];
    optional int32 max_width = 3 [default = 256];
    optional int32 max_height = 4 [default = 256];
}

message ROIAlignPoolingParameter {
    // Pad, kernel size, and stride are all given as a single value for equal
    // dimensions in height and width or as Y, X pairs.
    optional uint32 pooled_h = 1 [default = 0]; // The pooled output height
    optional uint32 pooled_w = 2 [default = 0]; // The pooled output width
    // Multiplicative spatial scale factor to translate ROI coords from their
    // input scale to the scale used when pooling
    optional float spatial_scale = 3 [default = 1];
    optional int32 sample_num = 4 [default = 1];
}

message ROIAlignPoolingPodParameter {
    // Pad, kernel size, and stride are all given as a single value for equal
    // dimensions in height and width or as Y, X pairs.
    optional uint32 pooled_h = 1 [default = 0]; // The pooled output height
    optional uint32 pooled_w = 2 [default = 0]; // The pooled output width
    // Multiplicative spatial scale factor to translate ROI coords from their
    // input scale to the scale used when pooling
    optional float spatial_scale = 3 [default = 1];
    optional int32 sample_num = 4 [default = 1];
}

message PSROIAlignPoolingParameter {
    required float spatial_scale = 1;
    required int32 output_dim = 2; // output channel number
    required int32 group_size = 3; // equal to pooled_size
    optional int32 sample_num = 4 [default = 1];
}

message UnpoolingParameter {
    enum UnpoolMethod {
        MAX = 0;
        AVE = 1;
        TILE= 2;
    }
    optional UnpoolMethod unpool = 1 [default = MAX]; // The pooling method
    // Pad, kernel size, and stride are all given as a single value for equal
    // dimensions in height and width or as Y, X pairs.
    optional uint32 pad = 4 [default = 0]; // The padding size (equal in Y, X)
    optional uint32 pad_h = 9 [default = 0]; // The padding height
    optional uint32 pad_w = 10 [default = 0]; // The padding width
    optional uint32 kernel_size = 2; // The kernel size (square)
    optional uint32 kernel_h = 5; // The kernel height
    optional uint32 kernel_w = 6; // The kernel width
    optional uint32 stride = 3 [default = 1]; // The stride (equal in Y, X)
    optional uint32 stride_h = 7; // The stride height
    optional uint32 stride_w = 8; // The stride width
    optional uint32 unpool_size = 12; // destined unpooled map size
    optional uint32 unpool_h = 13; // destined unpooled map height
    optional uint32 unpool_w = 14; // destined unpooled map width
    enum Engine {
        DEFAULT = 0;
        CAFFE = 1;
    }
    optional Engine engine = 11 [default = DEFAULT];
}

message ReverseParameter {
    optional int32 axis=1 [default=0];
}

message LSTMParameter {
    optional uint32 num_output = 1; // The number of outputs for the layer
    optional float clipping_threshold = 2 [default = 0.0];
    optional FillerParameter weight_filler = 3; // The filler for weight
    optional FillerParameter bias_filler = 4; // The filler for the bias
    optional uint32 batch_size = 5 [default = 1];
}

message PriorVBoxParameter {
    // Encode/decode type.
    // Minimum box size (in pixels). Required!
    repeated float height = 1;
    optional float width = 2 [default =16];

    // If true, will clip the prior so that it is within [0, 1]
    optional bool clip = 5 [default = false];
    // Variance for adjusting the prior bboxes.
    repeated float variance = 6;
    // By default, we calculate img_height, img_width, step_x, step_y based on
    // bottom[0] (feat) and bottom[1] (img). Unless these values are explicitely
    // provided.
    // Explicitly provide the img_size.
    optional uint32 img_size = 7;
    // Either img_size or img_h/img_w should be specified; not both.
    optional uint32 img_h = 8;
    optional uint32 img_w = 9;

    // Explicitly provide the step size.
    optional float step = 10;
    // Either step or step_h/step_w should be specified; not both.
    optional float step_h = 11;
    optional float step_w = 12;

    // Offset to the top left corner of each cell.
    optional float offset = 13 [default = 0.5];
}


message NNUpsampleParameter {
    optional uint32 resize = 1 [default = 2];
}

message BTCostVolumeParameter {
    optional int32 min_disparity = 1 [default = 0];
    optional uint32 disparity_num = 2 [default = 64];  // NOTE: disparity_num must be divided by 4
    optional bool   save_disparity = 3 [default = false];

    optional uint32 step_w  = 4  [default = 1];
    optional uint32 step_h  = 5  [default = 1];
    optional uint32 step_mode  = 6  [default = 0];   // 0 mean only calculate once, non 0 mean accumulate sum
    enum CostDomainType {
        SOBEL_ONLY = 0;
        IMAGE_ONLY = 1;
        SOBEL_AND_IMAGE = 2;
    }
    optional CostDomainType cost_domain_type = 7 [default = SOBEL_AND_IMAGE]; // SOBEL_AND_IMAGE is default correlation

    enum ImplementMode {
        GPU_MODE = 0;
        CPU_MODE = 1;
    }
    optional ImplementMode implement_mode = 8 [default = GPU_MODE];
}

// Message that stores parameters used by CorrelationLayer
message CorrelationParameter {
  optional uint32 pad = 2 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 kernel_size = 3; // The kernel size (square)
  optional uint32 max_displacement = 4; // The maximum displacement (square)
  optional uint32 stride_1 = 5 [default = 1]; // The stride in blob 1 (equal in Y, X)
  optional uint32 stride_2 = 6 [default = 1]; // The stride in blob 2 (equal in Y, X)

  // For Correlation1D:
  optional int32 single_direction = 8 [default = 0]; // Correlate only to the left (-1) or right (1)

  optional bool do_abs = 7 [default = false]; // Use absolute value of result
  enum CorrelationType {
    MULTIPLY = 0;
    SUBTRACT = 1;
  }
  optional CorrelationType correlation_type = 15 [default = MULTIPLY]; // Multiplicative is normal correlation
  optional int32 pad_shift = 16 [default = 0];
  optional bool mvn = 9 [default = false];
}

// Message that stores parameters used by PSROIPoolingLayer
message PSROIPoolingParameter {
    required float spatial_scale = 1;
    required int32 output_dim = 2; // output channel number
    required int32 group_size = 3; // equal to pooled_size
    optional float roi_scale = 4 [default = 1.0]; // scale for roi
}

message ScaleParameter {
    optional int32 axis = 1 [default = 1];
    optional int32 num_axes = 2 [default = 1];
    optional FillerParameter filler = 3;
    optional bool bias_term = 4 [default = false];
    optional FillerParameter bias_filler = 5;
}

message ScalesParameter {
    optional float alpha = 1 [default = 1];
    optional float beta = 2 [default = 0];
}

message TransposeParameter {
    repeated int32 dim = 1;
}

message ROIAlignParameter {
    // Pad, kernel size, and stride are all given as a single value for equal
    // dimensions in height and width or as Y, X pairs.
    optional uint32 pooled_h = 1 [default = 0]; // The pooled output height
    optional uint32 pooled_w = 2 [default = 0]; // The pooled output width
    // Multiplicative spatial scale factor to translate ROI coords from their
    // input scale to the scale used when pooling
    optional float spatial_scale = 3 [default = 1];
}

message RpnProposalLayerParameter {
    optional int32 feat_stride = 1 [default = 16];
    optional int32 allowed_border = 2 [default = 0];
    optional TestDescParam test_desc_param = 3;
    optional TrainDescParam train_desc_param = 4;
    repeated int32 anchor_scales = 5;
    repeated float anchor_ratios = 6;
    message TestDescParam {
        optional int32 rpn_pre_nms_top_n = 1 [default = 6000 ];
        optional int32 rpn_post_nms_top_n = 2 [default = 300 ];
        optional int32 rpn_min_size = 3 [default = 16 ];
        optional float rpn_nms_thresh = 4 [default = 0.7 ];
    }
    message TrainDescParam {
        optional int32 rpn_pre_nms_top_n = 1 [default = 12000 ];
        optional int32 rpn_post_nms_top_n = 2 [default = 2000 ];
        optional int32 rpn_min_size = 3 [default = 16 ];
        optional float rpn_nms_thresh = 4 [default = 0.7 ];
    }
    optional float score = 7 [default = 0];
    optional bool withOutSoftmax = 8 [default = false];
    optional float bbox_reg_xy_limit = 9 [default = 5.0 ];
    optional float bbox_reg_hw_temp = 10 [default = 1.0 ];
    optional float bbox_reg_hw_ratio_thresh_hi = 11 [default = 5.0 ];
    optional float bbox_reg_hw_ratio_thresh_lo = 12 [default = 0.2 ];
}

message ROIMaskPoolingParameter {
    optional int32 pooled_h = 1 [default = 0];
    optional int32 pooled_w = 2 [default = 0];
    optional float spatial_scale = 3 [default = 1];
    optional int32  half_part = 4 [default = 0];
    optional float roi_scale = 5 [default = 1];
    optional float mask_scale = 6 [default = 0];
}

message ZXYBNParameter {
    //! PPL Will ignore FillerParameter
    //! But caffe use Filler to init blobs_.
    optional FillerParameter slope_filler = 1;
    optional FillerParameter bias_filler = 2;
    optional float momentum  = 3 [default = 0.9];
    optional float eps = 4 [default = 1e-5];
    optional bool frozen = 5 [default = false];
    enum Engine {
        DEFAULT = 0;
        CAFFE = 1;
        CUDNN = 2;
    }
    optional Engine engine = 6 [default = DEFAULT];
}

// Message that stores parameters used to apply transformation
// to the data layer's data
message TransformationParameter {
  // For data pre-processing, we can do simple scaling and subtracting the
  // data mean, if provided. Note that the mean subtraction is always carried
  // out before scaling.
  optional float scale = 1 [default = 1];
  // Specify if we want to randomly mirror data.
  optional bool mirror = 2 [default = false];
  // Specify if we would like to randomly crop an image.
  optional uint32 crop_size = 3 [default = 0];
  // mean_file and mean_value cannot be specified at the same time
  optional string mean_file = 4;
  // if specified can be repeated once (would substract it from all the channels)
  // or can be repeated the same number of times as channels
  // (would subtract them from the corresponding channel)
  repeated float mean_value = 5;
}

// Message that stores parameters shared by loss layers
message LossParameter {
  // If specified, ignore instances with the given label.
  optional int32 ignore_label = 1;
  // If true, normalize each batch across all instances (including spatial
  // dimesions, but not ignored instances); else, divide by batch size only.
  optional bool normalize = 2 [default = true];
}

// Message that stores parameters used by AccuracyLayer
message AccuracyParameter {
  // When computing accuracy, count as correct by comparing the true label to
  // the top k scoring classes.  By default, only compare to the top scoring
  // class (i.e. argmax).
  optional uint32 top_k = 1 [default = 1];
}

// Message that stores parameters used by ArgMaxLayer
message ArgMaxParameter {
  // If true produce pairs (argmax, maxval)
  optional bool out_max_val = 1 [default = false];
  optional uint32 top_k = 2 [default = 1];
  optional int32 axis=3;
}

// Message that stores parameters used by ConcatLayer
message ConcatParameter {
  // The axis along which to concatenate -- may be negative to index from the
  // end (e.g., -1 for the last axis).  Other axes must have the
  // same dimension for all the bottom blobs.
  // By default, ConcatLayer concatenates blobs along the "channels" axis (1).
  optional int32 axis = 2 [default = 1];

  // DEPRECATED: alias for "axis" -- does not support negative indexing.
  optional uint32 concat_dim = 1 [default = 1];
}

// Message that stores parameters used by ContrastiveLossLayer
message ContrastiveLossParameter {
  //margin for dissimilar pair
  optional float margin = 1 [default = 1.0];
}

// Message that stores parameters used by ConvolutionLayer
message ConvolutionParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
  optional bool bias_term = 2 [default = true]; // whether to have bias terms
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pad = 3 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 pad_h = 9 [default = 0]; // The padding height
  optional uint32 pad_w = 10 [default = 0]; // The padding width
  optional uint32 kernel_size = 4; // The kernel size (square)
  optional uint32 kernel_h = 11; // The kernel height
  optional uint32 kernel_w = 12; // The kernel width
  optional uint32 group = 5 [default = 1]; // The group size for group conv
  optional uint32 stride = 6 [default = 1]; // The stride (equal in Y, X)
  optional uint32 stride_h = 13; // The stride height
  optional uint32 stride_w = 14; // The stride width
  optional uint32 hole = 17 [default = 1];
  optional uint32 hole_h = 18 [default = 1];
  optional uint32 hole_w = 19 [default = 1];
  optional FillerParameter weight_filler = 7; // The filler for the weight
  optional FillerParameter bias_filler = 8; // The filler for the bias
  enum Engine {
    DEFAULT = 0;
    CAFFE = 1;
    CUDNN = 2;
  }
  optional Engine engine = 15 [default = DEFAULT];
  enum PPLConvolutionForwardAlgo_t{
      PPL_CONVOLUTION_FORWARD_ALGO_NONE                     = -1;
      PPL_CONVOLUTION_FORWARD_ALGO_IMPLICIT_GEMM            = 0;
      PPL_CONVOLUTION_FORWARD_ALGO_IMPLICIT_PRECOMP_GEMM    = 1;
      PPL_CONVOLUTION_FORWARD_ALGO_GEMM                     = 2;
      PPL_CONVOLUTION_FORWARD_ALGO_DIRECT                   = 3;
      PPL_CONVOLUTION_FORWARD_ALGO_FFT                      = 4;
      PPL_CONVOLUTION_FORWARD_ALGO_FFT_TILING               = 5;
      PPL_CONVOLUTION_FORWARD_ALGO_WINOGRAD_BLK2X2          = 6;
      PPL_CONVOLUTION_FORWARD_ALGO_WINOGRAD_BLK4X4          = 7;
      PPL_CONVOLUTION_FORWARD_ALGO_WINOGRAD_BLK6X6          = 8;
      PPL_CONVOLUTION_FORWARD_ALGO_WINOGRAD_BLK4x4_FLT3x3   = 9;
      PPL_CONVOLUTION_FORWARD_ALGO_WINOGRAD_BLK4x4_FLT5X5   = 10;
      PPL_CONVOLUTION_FORWARD_ALGO_INVGEMM                  = 11;
  }
  optional PPLConvolutionForwardAlgo_t ForwardAlgo = 20 [default = PPL_CONVOLUTION_FORWARD_ALGO_NONE];
  optional int32 ntile_width = 72 [default = 1];
  optional int32 ntile_height = 73 [default = 1];
//  repeated QuantizeParameter quantize_param = 74;
  optional QuantizeParameter quantize_param = 74;
  //fusion relu for ReflectionPadConvolution [ocl]
  optional bool is_relu = 77 [default = false];
  repeated QuantizeParameter perchannel_quantize_param = 75;
  // out pad for pytorch deconv add by jianfei 20200824
  optional uint32 out_pad = 78 [default = 0]; // The out_padding size (equal in Y, X)
  optional uint32 out_pad_h = 79 [default = 0]; // The out_padding height
  optional uint32 out_pad_w = 80 [default = 0]; // The out_padding width
}

// Message that stores parameters used by DataLayer
message DataParameter {
  enum DB {
    LEVELDB = 0;
    LMDB = 1;
  }
  // Specify the data source.
  optional string source = 1;
  // Specify the batch size.
  optional uint32 batch_size = 4;
  // The rand_skip variable is for the data layer to skip a few data points
  // to avoid all asynchronous sgd clients to start at the same point. The skip
  // point would be set as rand_skip * rand(0,1). Note that rand_skip should not
  // be larger than the number of keys in the database.
  optional uint32 rand_skip = 7 [default = 0];
  optional DB backend = 8 [default = LEVELDB];
  // DEPRECATED. See TransformationParameter. For data pre-processing, we can do
  // simple scaling and subtracting the data mean, if provided. Note that the
  // mean subtraction is always carried out before scaling.
  optional float scale = 2 [default = 1];
  optional string mean_file = 3;
  // DEPRECATED. See TransformationParameter. Specify if we would like to randomly
  // crop an image.
  optional uint32 crop_size = 5 [default = 0];
  // DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
  // data.
  optional bool mirror = 6 [default = false];
  // Force the encoded image to have 3 color channels
  optional bool force_encoded_color = 9 [default = false];
}

 message NonMaximumSuppressionParameter {
   // Threshold to be used in nms.
   optional float nms_threshold = 1 [default = 0.3];
   // Maximum number of results to be kept.
   optional int32 top_k = 2;
 }

message SaveOutputParameter {
  // Output directory. If not empty, we will save the results.
  optional string output_directory = 1;
  // Output name prefix.
  optional string output_name_prefix = 2;
  // Output format.
  //    VOC - PASCAL VOC output format.
  //    COCO - MS COCO output format.
  optional string output_format = 3;
  // If you want to output results, must also provide the following two files.
  // Otherwise, we will ignore saving results.
  // label map file.
  optional string label_map_file = 4;
  // A file which contains a list of names and sizes with same order
  // of the input DB. The file is in the following format:
  //    name height width
  //    ...
  optional string name_size_file = 5;
  // Number of test images. It can be less than the lines specified in
  // name_size_file. For example, when we only want to evaluate on part
  // of the test images.
  optional uint32 num_test_image = 6;
}

// Message that store parameters used by DetectionOutputLayer
message DetectionOutputParameter {
  // Number of classes to be predicted. Required!
  optional uint32 num_classes = 1;
  // If true, bounding box are shared among different classes.
  optional bool share_location = 2 [default = true];
  // Background label id. If there is no background class,
  // set it as -1.
  optional int32 background_label_id = 3 [default = 0];
  // Parameters used for non maximum suppression.
  optional NonMaximumSuppressionParameter nms_param = 4;
  // Parameters used for saving detection results.
  optional SaveOutputParameter save_output_param = 5;
  // Type of coding method for bbox.
  optional PriorBoxParameter.CodeType code_type = 6 [default = CORNER];
  // If true, variance is encoded in target; otherwise we need to adjust the
  // predicted offset accordingly.
  optional bool variance_encoded_in_target = 8 [default = false];
  // Number of total bboxes to be kept per image after nms step.
  // -1 means keeping all bboxes after nms step.
  optional int32 keep_top_k = 7 [default = -1];
  // Only consider detections whose confidences are larger than a threshold.
  // If not provided, consider all boxes.
  optional float confidence_threshold = 9;
  // If true, visualize the detection results.
  optional bool visualize = 10 [default = false];
  // The threshold used to visualize the detection results.
  optional float visualize_threshold = 11;
}

// Message that stores parameters used by DropoutLayer
message DropoutParameter {
  optional float dropout_ratio = 1 [default = 0.5]; // dropout ratio
}

// Message that stores parameters used by DummyDataLayer.
// DummyDataLayer fills any number of arbitrarily shaped blobs with random
// (or constant) data generated by "Fillers" (see "message FillerParameter").
message DummyDataParameter {
  // This layer produces N >= 1 top blobs.  DummyDataParameter must specify 1 or N
  // shape fields, and 0, 1 or N data_fillers.
  //
  // If 0 data_fillers are specified, ConstantFiller with a value of 0 is used.
  // If 1 data_filler is specified, it is applied to all top blobs.  If N are
  // specified, the ith is applied to the ith top blob.
  repeated FillerParameter data_filler = 1;
  repeated BlobShape shape = 6;

  // 4D dimensions -- deprecated.  Use "shape" instead.
  repeated uint32 num = 2;
  repeated uint32 channels = 3;
  repeated uint32 height = 4;
  repeated uint32 width = 5;
}

// Message that stores parameters used by EltwiseLayer
message EltwiseParameter {
  enum EltwiseOp {
    PROD = 0;
    SUM = 1;
    MAX = 2;
  }
  optional EltwiseOp operation = 1 [default = SUM]; // element-wise operation
  repeated float coeff = 2; // blob-wise coefficient for SUM operation

  // Whether to use an asymptotically slower (for >2 inputs) but stabler method
  // of computing the gradient for the PROD operation. (No effect for SUM op.)
  optional bool stable_prod_grad = 3 [default = true];
}

// Message that stores parameters used by ExpLayer
message ExpParameter {
  // ExpLayer computes outputs y = base ^ (shift + scale * x), for base > 0.
  // Or if base is set to the default (-1), base is set to e,
  // so y = exp(shift + scale * x).
  optional float base = 1 [default = -1.0];
  optional float scale = 2 [default = 1.0];
  optional float shift = 3 [default = 0.0];
}

// Message that stores parameters used by ExpLayer
message LogParameter {
  // LogLayer computes outputs y = log_base(shift + scale * x), for base > 0.
  // Or if base is set to the default (-1), base is set to e,
  // so y = ln(shift + scale * x) = log_e(shift + scale * x)
  optional float base = 1 [default = -1.0];
  optional float scale = 2 [default = 1.0];
  optional float shift = 3 [default = 0.0];
}

// Message that stores parameters used by HDF5DataLayer
message HDF5DataParameter {
  // Specify the data source.
  optional string source = 1;
  // Specify the batch size.
  optional uint32 batch_size = 2;
}

// Message that stores parameters used by HDF5OutputLayer
message HDF5OutputParameter {
  optional string file_name = 1;
}

message HingeLossParameter {
  enum Norm {
    L1 = 1;
    L2 = 2;
  }
  // Specify the Norm to use L1 or L2
  optional Norm norm = 1 [default = L1];
}

// Message that stores parameters used by ImageDataLayer
message ImageDataParameter {
  // Specify the data source.
  optional string source = 1;
  // Specify the batch size.
  optional uint32 batch_size = 4;
  // The rand_skip variable is for the data layer to skip a few data points
  // to avoid all asynchronous sgd clients to start at the same point. The skip
  // point would be set as rand_skip * rand(0,1). Note that rand_skip should not
  // be larger than the number of keys in the database.
  optional uint32 rand_skip = 7 [default = 0];
  // Whether or not ImageLayer should shuffle the list of files at every epoch.
  optional bool shuffle = 8 [default = false];
  // It will also resize images if new_height or new_width are not zero.
  optional uint32 new_height = 9 [default = 0];
  optional uint32 new_width = 10 [default = 0];
  // Specify if the images are color or gray
  optional bool is_color = 11 [default = true];
  // DEPRECATED. See TransformationParameter. For data pre-processing, we can do
  // simple scaling and subtracting the data mean, if provided. Note that the
  // mean subtraction is always carried out before scaling.
  optional float scale = 2 [default = 1];
  optional string mean_file = 3;
  // DEPRECATED. See TransformationParameter. Specify if we would like to randomly
  // crop an image.
  optional uint32 crop_size = 5 [default = 0];
  // DEPRECATED. See TransformationParameter. Specify if we want to randomly mirror
  // data.
  optional bool mirror = 6 [default = false];
  optional string root_folder = 12 [default = ""];
}

// Message that stores parameters InfogainLossLayer
message InfogainLossParameter {
  // Specify the infogain matrix source.
  optional string source = 1;
}

// Message that stores parameters used by InnerProductLayer
message InnerProductParameter {
  optional uint32 num_output = 1; // The number of outputs for the layer
  optional bool bias_term = 2 [default = true]; // whether to have bias terms
  optional FillerParameter weight_filler = 3; // The filler for the weight
  optional FillerParameter bias_filler = 4; // The filler for the bias

  // The first axis to be lumped into a single inner product computation;
  // all preceding axes are retained in the output.
  // May be negative to index from the end (e.g., -1 for the last axis).
  optional int32 axis = 5 [default = 1];
  optional QuantizeParameter quantize_param = 6;
  repeated QuantizeParameter perchannel_quantize_param = 7;
}

// Message that stores parameters used by LRNLayer
message LRNParameter {
  optional uint32 local_size = 1 [default = 5];
  optional float alpha = 2 [default = 1.];
  optional float beta = 3 [default = 0.75];
  enum NormRegion {
    ACROSS_CHANNELS = 0;
    WITHIN_CHANNEL = 1;
  }
  optional NormRegion norm_region = 4 [default = ACROSS_CHANNELS];
  optional float k = 5 [default = 1.];
}

// Message that stores parameters used by MemoryDataLayer
message MemoryDataParameter {
  optional uint32 batch_size = 1;
  optional uint32 channels = 2;
  optional uint32 height = 3;
  optional uint32 width = 4;
}

// Message that stores parameters used by MVNLayer
message MVNParameter {
  // This parameter can be set to false to normalize mean only
  optional bool normalize_variance = 1 [default = true];

  // This parameter can be set to true to perform DNN-like MVN
  optional bool across_channels = 2 [default = false];
}

message PermuteParameter {
  // The new orders of the axes of data. Notice it should be with
  // in the same range as the input data, and it starts from 0.
  // Do not provide repeated order.
  repeated uint32 order = 1;
}

// Message that stores parameters used by PoolingLayer
message PoolingParameter {
  enum PoolMethod {
    MAX = 0;
    AVE = 1;
    STOCHASTIC = 2;
    AVE_COUNT_INCLUDE_PADDING = 3;
    AVE_COUNT_EXCLUDE_PADDING = 4;
  }
  optional PoolMethod pool = 1 [default = MAX]; // The pooling method
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pad = 4 [default = 0]; // The padding size (equal in Y, X)
  optional uint32 pad_h = 9 [default = 0]; // The padding height
  optional uint32 pad_w = 10 [default = 0]; // The padding width
  optional uint32 kernel_size = 2; // The kernel size (square)
  optional uint32 kernel_h = 5; // The kernel height
  optional uint32 kernel_w = 6; // The kernel width
  optional uint32 stride = 3 [default = 1]; // The stride (equal in Y, X)
  optional uint32 stride_h = 7; // The stride height
  optional uint32 stride_w = 8; // The stride width
  enum Engine {
    DEFAULT = 0;
    CAFFE = 1;
    CUDNN = 2;
  }
  optional Engine engine = 11 [default = DEFAULT];
  // If global_pooling then it will pool over the size of the bottom by doing
  // kernel_h = bottom->height and kernel_w = bottom->width
  optional bool global_pooling = 12 [default = false];
  optional bool ceil_mode = 13 [default = true];
}

message PoolingSpecificParameter{
  enum PoolSpecificMethod {
    MAX = 0;
    AVE = 1;
  }
  required PoolSpecificMethod pool = 1;
  required uint32 spe_w = 2;
  required uint32 spe_h = 3;
}
// Message that stores parameters used by PowerLayer
message PowerParameter {
  // PowerLayer computes outputs y = (shift + scale * x) ^ power.
  optional float power = 1 [default = 1.0];
  optional float scale = 2 [default = 1.0];
  optional float shift = 3 [default = 0.0];
}

// Message that store parameters used by PriorBoxLayer
message PriorBoxParameter {
  // Encode/decode type.
  enum CodeType {
    CORNER = 1;
    CENTER_SIZE = 2;
  }
  // Minimum box size (in pixels). Required!
  optional float min_size = 1;
  // Maximum box size (in pixels). Required!
  optional float max_size = 2;
  // Various of aspect ratios. Duplicate ratios will be ignored.
  // If none is provided, we use default ratio 1.
  repeated float aspect_ratio = 3;
  // If true, will flip each aspect ratio.
  // For example, if there is aspect ratio "r",
  // we will generate aspect ratio "1.0/r" as well.
  optional bool flip = 4 [default = true];
  // If true, will clip the prior so that it is within [0, 1]
  optional bool clip = 5 [default = true];
  // Variance for adjusting the prior bboxes.
  repeated float variance = 6;
}

// Message that stores parameters used by PythonLayer
message PythonParameter {
  optional string module = 1;
  optional string layer = 2;
}

// Message that stores parameters used by ReLULayer
message ReLUParameter {
  // Allow non-zero slope for negative inputs to speed up optimization
  // Described in:
  // Maas, A. L., Hannun, A. Y., & Ng, A. Y. (2013). Rectifier nonlinearities
  // improve neural network acoustic models. In ICML Workshop on Deep Learning
  // for Audio, Speech, and Language Processing.
  optional float negative_slope = 1 [default = 0];
  enum Engine {
    DEFAULT = 0;
    CAFFE = 1;
    CUDNN = 2;
  }
  optional Engine engine = 2 [default = DEFAULT];
}

// Message that stores parameters used by ROIPoolingLayer
message ROIPoolingParameter {
  // Pad, kernel size, and stride are all given as a single value for equal
  // dimensions in height and width or as Y, X pairs.
  optional uint32 pooled_h = 1 [default = 0]; // The pooled output height
  optional uint32 pooled_w = 2 [default = 0]; // The pooled output width
  // Multiplicative spatial scale factor to translate ROI coords from their
  // input scale to the scale used when pooling
  optional float spatial_scale = 3 [default = 1];
}

message ReshapeParameter {
  // Specify the output dimensions. If some of the dimensions are set to 0,
  // the corresponding dimension from the bottom layer is used (unchanged).
  // Exactly one dimension may be set to -1, in which case its value is
  // inferred from the count of the bottom blob and the remaining dimensions.
  // For example, suppose we want to reshape a 2D blob "input" with shape 2 x 8:
  //
  //   layer {
  //     type: "Reshape" bottom: "input" top: "output"
  //     reshape_param { ... }
  //   }
  //
  // If "input" is 2D with shape 2 x 8, then the following reshape_param
  // specifications are all equivalent, producing a 3D blob "output" with shape
  // 2 x 2 x 4:
  //
  //   reshape_param { shape { dim:  2  dim: 2  dim:  4 } }
  //   reshape_param { shape { dim:  0  dim: 2  dim:  4 } }
  //   reshape_param { shape { dim:  0  dim: 2  dim: -1 } }
  //   reshape_param { shape { dim: -1  dim: 0  dim:  2 } }
  //
  optional BlobShape shape = 1;

  // axis and num_axes control the portion of the bottom blob's shape that are
  // replaced by (included in) the reshape. By default (axis == 0 and
  // num_axes == -1), the entire bottom blob shape is included in the reshape,
  // and hence the shape field must specify the entire output shape.
  //
  // axis may be non-zero to retain some portion of the beginning of the input
  // shape (and may be negative to index from the end; e.g., -1 to begin the
  // reshape after the last axis, including nothing in the reshape,
  // -2 to include only the last axis, etc.).
  //
  // For example, suppose "input" is a 2D blob with shape 2 x 8.
  // Then the following ReshapeLayer specifications are all equivalent,
  // producing a blob "output" with shape 2 x 2 x 4:
  //
  //   reshape_param { shape { dim: 2  dim: 2  dim: 4 } }
  //   reshape_param { shape { dim: 2  dim: 4 } axis:  1 }
  //   reshape_param { shape { dim: 2  dim: 4 } axis: -3 }
  //
  // num_axes specifies the extent of the reshape.
  // If num_axes >= 0 (and axis >= 0), the reshape will be performed only on
  // input axes in the range [axis, axis+num_axes].
  // num_axes may also be -1, the default, to include all remaining axes
  // (starting from axis).
  //
  // For example, suppose "input" is a 2D blob with shape 2 x 8.
  // Then the following ReshapeLayer specifications are equivalent,
  // producing a blob "output" with shape 1 x 2 x 8.
  //
  //   reshape_param { shape { dim:  1  dim: 2  dim:  8 } }
  //   reshape_param { shape { dim:  1  dim: 2  }  num_axes: 1 }
  //   reshape_param { shape { dim:  1  }  num_axes: 0 }
  //
  // On the other hand, these would produce output blob shape 2 x 1 x 8:
  //
  //   reshape_param { shape { dim: 2  dim: 1  dim: 8  }  }
  //   reshape_param { shape { dim: 1 }  axis: 1  num_axes: 0 }
  //
  optional int32 axis = 2 [default = 0];
  optional int32 num_axes = 3 [default = -1];
}

// Message that stores parameters used by SigmoidLayer
message SigmoidParameter {
  enum Engine {
    DEFAULT = 0;
    CAFFE = 1;
    CUDNN = 2;
  }
  optional Engine engine = 1 [default = DEFAULT];
}

// Message that stores parameters used by SliceLayer
message SliceParameter {
  // The axis along which to slice -- may be negative to index from the end
  // (e.g., -1 for the last axis).
  // By default, SliceLayer concatenates blobs along the "channels" axis (1).
  optional int32 axis = 3 [default = 1];
  repeated uint32 slice_point = 2;

  // DEPRECATED: alias for "axis" -- does not support negative indexing.
  optional uint32 slice_dim = 1 [default = 1];
}

// Message that stores parameters used by SoftmaxLayer, SoftmaxWithLossLayer
message SoftmaxParameter {
  enum Engine {
    DEFAULT = 0;
    CAFFE = 1;
    CUDNN = 2;
  }
  optional Engine engine = 1 [default = DEFAULT];

  // The axis along which to perform the softmax -- may be negative to index
  // from the end (e.g., -1 for the last axis).
  // Any other axes will be evaluated as independent softmaxes.
  optional int32 axis = 2 [default = 1];
}

// Message that stores parameters used by TanHLayer
message TanHParameter {
  enum Engine {
    DEFAULT = 0;
    CAFFE = 1;
    CUDNN = 2;
  }
  optional Engine engine = 1 [default = DEFAULT];
}

// Message that stores parameters used by ThresholdLayer
message ThresholdParameter {
  optional float threshold = 1 [default = 0]; // Strictly positive values
}

// Message that stores parameters used by WindowDataLayer
message WindowDataParameter {
  // Specify the data source.
  optional string source = 1;
  // For data pre-processing, we can do simple scaling and subtracting the
  // data mean, if provided. Note that the mean subtraction is always carried
  // out before scaling.
  optional float scale = 2 [default = 1];
  optional string mean_file = 3;
  // Specify the batch size.
  optional uint32 batch_size = 4;
  // Specify if we would like to randomly crop an image.
  optional uint32 crop_size = 5 [default = 0];
  // Specify if we want to randomly mirror data.
  optional bool mirror = 6 [default = false];
  // Foreground (object) overlap threshold
  optional float fg_threshold = 7 [default = 0.5];
  // Background (non-object) overlap threshold
  optional float bg_threshold = 8 [default = 0.5];
  // Fraction of batch that should be foreground objects
  optional float fg_fraction = 9 [default = 0.25];
  // Amount of contextual padding to add around a window
  // (used only by the window_data_layer)
  optional uint32 context_pad = 10 [default = 0];
  // Mode for cropping out a detection window
  // warp: cropped window is warped to a fixed size and aspect ratio
  // square: the tightest square around the window is cropped
  optional string crop_mode = 11 [default = "warp"];
  // cache_images: will load all images in memory for faster access
  optional bool cache_images = 12 [default = false];
  // append root_folder to locate images
  optional string root_folder = 13 [default = ""];
}

// Added 2015/7/7
message BNParameter {
  optional FillerParameter scale_filler = 1; // The initial filler for the scale
  optional FillerParameter shift_filler = 2; // The initial filler for the shift
  optional float var_eps = 3 [default = 1e-10]; // The epsilon added to variance
  optional bool moving_average = 4 [default = false]; // whether or not using moving average for inference
  optional float decay = 5 [default = 0.05]; // The decay factor for moving average
}

// CTC parameter
message CTCParameter {
  optional float threshold = 1 [default = 0.7];
  enum Decoder {
    best_path = 0;
    best_path_thres = 1;
    prefix_search = 2;
  }
  optional Decoder decode_type = 2[default = best_path];
}

message PReLUParameter {
  // Parametric ReLU described in K. He et al, Delving Deep into Rectifiers:
  // Surpassing Human-Level Performance on ImageNet Classification, 2015.

  // Initial value of a_i. Default is a_i=0.25 for all i.
  optional FillerParameter filler = 1;
  // Whether or not slope paramters are shared across channels.
  optional bool channel_shared = 2 [default = false];
  optional QuantizeParameter quantize_param = 3;
}

message CropParameter{
   enum Type {
    CENTER = 1;
    RANDOM = 2;
   }
   optional Type type = 1 [default = CENTER];
   optional uint32 crop_w = 2 [default = 0];
   optional uint32 crop_h = 3 [default = 0];
   optional bool  print_info = 4 [default = false];
}

message AffineTransParameter {
  optional uint32 output_h = 1 [default = 0];
  optional uint32 output_w = 2 [default = 0];
  optional float border_value = 3 [default = 0];
  repeated float affine_mat = 4;
  optional float scale = 5 [default = 1.0];
  optional float translate_x = 6 [default = 0.0];
  optional float translate_y = 7 [default = 0.0];
}

message AffineTransPointParameter {
  optional bool inverse = 1 [default = false];
  optional float translate_x = 2 [default = 0.0];
  optional float translate_y = 3 [default = 0.0];
  repeated float affine_mat = 4;
  optional float scale = 5 [default = 1.0];
}

message CalcAffineMatParameter {
  repeated float landmark_x = 1;
  repeated float landmark_y = 2;
}

enum InterpType {
  INTERP_BILINEAR = 0;
  INTERP_NEAREST = 1;
}

// ROI Layer
// Use this layer to crop a ROI in feature map.
//
// Input 1: Feature Map
// Input 2: ROI center (required when center isn't given in parameter)
//    This layer support multi-center, and the output channels will be orginazed by
//    input center first (channel1-center1, channel2-center1, ... , channel1-center2, channel2-center2, ...)
//
// Output 1: ROI Feature Map
// Output 2: Actually used center subtract given center (available when type=NEAREST)
//
// Parameter:
//    crop_h, crop_w: ROI's size.
//    center_x, center_y: ROI's center, optional.
//    type: Interpolation type when applying ROI.
//       BILINEAR: The ROI's center will be the center sepcified exactly. And bilinear interpolation will be applied when crop.
//       NEAREST: Nearest interpolation will be applied when crop. Thus, the ROI's center can't be exactly equal to the center sepcified.
//          And the difference will be output in the top[1];
//
// Note:
//    ROI's size won't change after crop. It's not a pooling method.

message ROIParameter {
  required uint32 crop_h = 1;
  required uint32 crop_w = 2;
  repeated float center_x = 3;
  repeated float center_y = 4;
  optional InterpType type = 5 [default = INTERP_BILINEAR];
}

// Message that stores parameters used by InterpLayer
message InterpParameter {
  optional int32 height = 1 [default = 0]; // Height of output
  optional int32 width = 2 [default = 0]; // Width of output
  optional int32 zoom_factor = 3 [default = 1]; // zoom factor
  optional int32 shrink_factor = 4 [default = 1]; // shrink factor
  optional int32 pad_beg = 5 [default = 0]; // padding at begin of input
  optional int32 pad_end = 6 [default = 0]; // padding at end of input
  optional bool  align_corners = 7 [default = true];
}

// Message that stores parameters used by RecurrentLayer
message RecurrentParameter {
  // The dimension of the output (and usually hidden state) representation --
  // must be explicitly set to not-zero.
  optional uint32 num_output = 1 [default = 0];

  optional FillerParameter weight_filler = 2; // The filler for the weight
  optional FillerParameter bias_filler = 3; // The filler for the bias

  // Whether to enable displaying debug_info in the unrolled recurrent net.
  optional bool debug_info = 4 [default = false];
}

/// Message that stores parameters used by FlattenLayer
message FlattenParameter {
  // The first axis to flatten: all preceding axes are retained in the output.
  // May be negative to index from the end (e.g., -1 for the last axis).
  optional int32 axis = 1 [default = 1];

  // The last axis to flatten: all following axes are retained in the output.
  // May be negative to index from the end (e.g., the default -1 for the last
  // axis).
  optional int32 end_axis = 2 [default = -1];
}

message BatchNormParameter {
  // If false, accumulate global mean/variance values via a moving average. If
  // true, use those accumulated values instead of computing mean/variance
  // across the batch.
  optional bool use_global_stats = 1;
  // How much does the moving average decay each iteration?
  optional float moving_average_fraction = 2 [default = .999];
  // Small value to add to the variance estimate so that we don't divide by
  // zero.
  optional float eps = 3 [default = 1e-5];
}

// DEPRECATED: use LayerParameter.
message V1LayerParameter {
  repeated string bottom = 2;
  repeated string top = 3;
  optional string name = 4;
  repeated NetStateRule include = 32;
  repeated NetStateRule exclude = 33;
  enum LayerType {
    NONE = 0;
    ABSVAL = 35;
    ACCURACY = 1;
    ARGMAX = 30;
    BNLL = 2;
    CONCAT = 3;
    CONTRASTIVE_LOSS = 37;
    CONVOLUTION = 4;
    DATA = 5;
    DECONVOLUTION = 39;
    DROPOUT = 6;
    DUMMY_DATA = 32;
    EUCLIDEAN_LOSS = 7;
    ELTWISE = 25;
    EXP = 38;
    FLATTEN = 8;
    HDF5_DATA = 9;
    HDF5_OUTPUT = 10;
    HINGE_LOSS = 28;
    IM2COL = 11;
    IMAGE_DATA = 12;
    INFOGAIN_LOSS = 13;
    INNER_PRODUCT = 14;
    LRN = 15;
    MEMORY_DATA = 29;
    MULTINOMIAL_LOGISTIC_LOSS = 16;
    MVN = 34;
    POOLING = 17;
    POWER = 26;
    RELU = 18;
    SIGMOID = 19;
    SIGMOID_CROSS_ENTROPY_LOSS = 27;
    SILENCE = 36;
    SOFTMAX = 20;
    SOFTMAX_LOSS = 21;
    SPLIT = 22;
    SLICE = 33;
    TANH = 23;
    WINDOW_DATA = 24;
    THRESHOLD = 31;
  }
  optional LayerType type = 5;
  repeated BlobProto blobs = 6;
  repeated string param = 1001;
  repeated DimCheckMode blob_share_mode = 1002;
  enum DimCheckMode {
    STRICT = 0;
    PERMISSIVE = 1;
  }
  repeated float blobs_lr = 7;
  repeated float weight_decay = 8;
  repeated float loss_weight = 35;
  optional AccuracyParameter accuracy_param = 27;
  optional ArgMaxParameter argmax_param = 23;
  optional ConcatParameter concat_param = 9;
  optional ContrastiveLossParameter contrastive_loss_param = 40;
  optional ConvolutionParameter convolution_param = 10;
  optional DataParameter data_param = 11;
  optional DropoutParameter dropout_param = 12;
  optional DummyDataParameter dummy_data_param = 26;
  optional EltwiseParameter eltwise_param = 24;
  optional ExpParameter exp_param = 41;
  optional HDF5DataParameter hdf5_data_param = 13;
  optional HDF5OutputParameter hdf5_output_param = 14;
  optional HingeLossParameter hinge_loss_param = 29;
  optional ImageDataParameter image_data_param = 15;
  optional InfogainLossParameter infogain_loss_param = 16;
  optional InnerProductParameter inner_product_param = 17;
  optional LRNParameter lrn_param = 18;
  optional MemoryDataParameter memory_data_param = 22;
  optional MVNParameter mvn_param = 34;
  optional PoolingParameter pooling_param = 19;
  optional PowerParameter power_param = 21;
  optional ReLUParameter relu_param = 30;
  optional SigmoidParameter sigmoid_param = 38;
  optional SoftmaxParameter softmax_param = 39;
  optional SliceParameter slice_param = 31;
  optional TanHParameter tanh_param = 37;
  optional ThresholdParameter threshold_param = 25;
  optional WindowDataParameter window_data_param = 20;
  optional TransformationParameter transform_param = 36;
  optional LossParameter loss_param = 42;
  optional V0LayerParameter layer = 1;
}

// DEPRECATED: V0LayerParameter is the old way of specifying layer parameters
// in Caffe.  We keep this message type around for legacy support.
message V0LayerParameter {
  optional string name = 1; // the layer name
  optional string type = 2; // the string to specify the layer type

  // Parameters to specify layers with inner products.
  optional uint32 num_output = 3; // The number of outputs for the layer
  optional bool biasterm = 4 [default = true]; // whether to have bias terms
  optional FillerParameter weight_filler = 5; // The filler for the weight
  optional FillerParameter bias_filler = 6; // The filler for the bias

  optional uint32 pad = 7 [default = 0]; // The padding size
  optional uint32 kernelsize = 8; // The kernel size
  optional uint32 group = 9 [default = 1]; // The group size for group conv
  optional uint32 stride = 10 [default = 1]; // The stride
  enum PoolMethod {
    MAX = 0;
    AVE = 1;
    STOCHASTIC = 2;
  }
  optional PoolMethod pool = 11 [default = MAX]; // The pooling method
  optional float dropout_ratio = 12 [default = 0.5]; // dropout ratio

  optional uint32 local_size = 13 [default = 5]; // for local response norm
  optional float alpha = 14 [default = 1.]; // for local response norm
  optional float beta = 15 [default = 0.75]; // for local response norm
  optional float k = 22 [default = 1.];

  // For data layers, specify the data source
  optional string source = 16;
  // For data pre-processing, we can do simple scaling and subtracting the
  // data mean, if provided. Note that the mean subtraction is always carried
  // out before scaling.
  optional float scale = 17 [default = 1];
  optional string meanfile = 18;
  // For data layers, specify the batch size.
  optional uint32 batchsize = 19;
  // For data layers, specify if we would like to randomly crop an image.
  optional uint32 cropsize = 20 [default = 0];
  // For data layers, specify if we want to randomly mirror data.
  optional bool mirror = 21 [default = false];

  // The blobs containing the numeric parameters of the layer
  repeated BlobProto blobs = 50;
  // The ratio that is multiplied on the global learning rate. If you want to
  // set the learning ratio for one blob, you need to set it for all blobs.
  repeated float blobs_lr = 51;
  // The weight decay that is multiplied on the global weight decay.
  repeated float weight_decay = 52;

  // The rand_skip variable is for the data layer to skip a few data points
  // to avoid all asynchronous sgd clients to start at the same point. The skip
  // point would be set as rand_skip * rand(0,1). Note that rand_skip should not
  // be larger than the number of keys in the database.
  optional uint32 rand_skip = 53 [default = 0];

  // Fields related to detection (det_*)
  // foreground (object) overlap threshold
  optional float det_fg_threshold = 54 [default = 0.5];
  // background (non-object) overlap threshold
  optional float det_bg_threshold = 55 [default = 0.5];
  // Fraction of batch that should be foreground objects
  optional float det_fg_fraction = 56 [default = 0.25];

  // optional bool OBSOLETE_can_clobber = 57 [default = true];

  // Amount of contextual padding to add around a window
  // (used only by the window_data_layer)
  optional uint32 det_context_pad = 58 [default = 0];

  // Mode for cropping out a detection window
  // warp: cropped window is warped to a fixed size and aspect ratio
  // square: the tightest square around the window is cropped
  optional string det_crop_mode = 59 [default = "warp"];

  // For ReshapeLayer, one needs to specify the new dimensions.
  optional int32 new_num = 60 [default = 0];
  optional int32 new_channels = 61 [default = 0];
  optional int32 new_height = 62 [default = 0];
  optional int32 new_width = 63 [default = 0];

  // Whether or not ImageLayer should shuffle the list of files at every epoch.
  // It will also resize images if new_height or new_width are not zero.
  optional bool shuffle_images = 64 [default = false];

  // For ConcatLayer, one needs to specify the dimension for concatenation, and
  // the other dimensions must be the same for all the bottom blobs.
  // By default it will concatenate blobs along the channels dimension.
  optional uint32 concat_dim = 65 [default = 1];

  optional int32 ntile_width = 72 [default = 1];
  optional int32 ntile_height = 73 [default = 1];
  optional HDF5OutputParameter hdf5_output_param = 1001;
}

message ChannelShuffleParameter {
    required uint32 group = 1 [default = 1];
}

message MovingAvgParameter {
    required float decay = 1 [default = 0.0];
}

message SlicingParameter{
  optional uint32 coefficient_len = 1 [default = 1];
  optional int32 depth_d = 2 [default = -1];     // the grid depth to be considered.
  optional float scale_x = 3 [default = -1.0];   // scale in range [0, 1] along width
  optional float scale_y = 4 [default = -1.0];   // scale in range [0, 1] along height
  optional int32 offset_x = 5 [default = 0];     // padding(or offset) along width
  optional int32 offset_y = 6 [default = 0];     // padding(or offset) along height
  optional int32 offset_z = 7 [default = 0];     // padding(or offset) along depth
}

message BilateralSlicingParameter
{
  required uint32 coefficient_len = 1 [default = 1];
}

message BilateralSliceApplyParameter
{
  required uint32 coefficient_len = 1 [default = 2];
  optional bool has_offset = 2 [default = true];
}

message AdaptiveBilateralSliceApplyParameter
{
  optional uint32 coefficient_len = 1 [default = 2];
  optional bool has_offset = 2 [default = true];
  optional int32 depth_d = 3 [default = 1];
}

message PointsCurveParameter
{
  optional uint32 numpoints = 1 [default = 16];
  optional FillerParameter slope_filler = 2; // The filler for the slope
  optional FillerParameter bias_filler = 3; // The filler for the bias
}

message SubpixelDownParameter {
  optional uint32 downsample = 1 [default=1];
}

message SubpixelUpParameter {
  enum DataType {
      FLOAT32 = 0;
      UINT8 = 1;
  }
  enum ModeType {
    caffe = 0;
    pytorch = 1;
  }
  optional uint32 upsample = 1 [default=1];
  optional DataType output_datatype = 2 [default=FLOAT32];
  optional ModeType mode = 3 [default=pytorch];
}

message ClipParameter {
  optional float min = 1;
  optional float max = 2;
}

message EltwiseAffineTransformParameter {
}

// Message that stores parameters used by TileLayer
message TileParameter {
  // The index of the axis to tile.
  optional int32 axis = 1 [default = 1];

  // The number of copies (tiles) of the blob to output.
  required int32 tiles = 2 [default = 1];
}

message ReduceParameter {
  enum ReduceOp {
    MEAN = 0;
  }
  // The index of the axis to tile.
  optional int32 axis = 1 [default = 1];

  // The number of copies (tiles) of the blob to output.
  optional int32 mode = 2 [default = 0];
}
message PadParameter {
    optional int32 pad = 1 [default = 0];
    enum PadMode {
        REFLECTION = 1;
    }
    optional PadMode mode = 2 [default = REFLECTION];
    optional int32 pad_w = 3 [default = 0];
    optional int32 pad_h = 4 [default = 0];
}
message ReLU6Parameter {
  // Allow non-zero slope for negative inputs to speed up optimization
  // Described in:
  // Maas, A. L., Hannun, A. Y., & Ng, A. Y. (2013). Rectifier nonlinearities
  // improve neural network acoustic models. In ICML Workshop on Deep Learning
  // for Audio, Speech, and Language Processing.
  optional float negative_slope = 1 [default = 0];
}

message Correlation2DParameter {
        optional uint32 groups = 1 [default = 1]; // groups size per batch
}

message MatMulParameter {
    enum MatMulMode {
        NN = 1;
        NT = 2;
        TN = 3;
        TT = 4;
    }
    optional MatMulMode mode = 1 [default = NN]; // gemm mode
}

message ParameterParameter {
    optional int32 batch = 1 [default = 1];
    optional int32 m = 2 [default = -1];
    optional int32 n = 3 [default = -1];
    optional int32 channel = 4 [default = -1];
    optional int32 height = 5 [default = -1];
    optional int32 width = 6 [default = -1];
}

message PixelShuffleParameter {
    required int32 upscale_factor = 1 [default = 1];
}

message ROITransformParameter {
    required int32 roi_pooled_h = 1;
    required int32 roi_pooled_w = 2;
}

message MainTransformParameter {
    required int32 roi_pooled_h = 1;
    required int32 roi_pooled_w = 2;
}

message InstanceNormParameter {
    optional int32 num_features = 1;
    optional float eps = 2 [default = 1e-5];
    optional bool affine = 3 [default = false];
}
message GridSampleParameter {
    enum PaddingMode {
        ZEROS = 0;
        BORDER = 1;
    }
    optional PaddingMode padding_mode = 1 [default = ZEROS];
}
message GridSample3DParameter {
    enum PaddingMode {
        ZEROS = 0;
        BORDER = 1;
    }
    optional PaddingMode padding_mode = 1 [default = ZEROS];
    optional bool align_corners = 2 [default = false];
    required int32 output_channel = 3;
}

message ReduceL2Parameter {
    optional int32 axes = 1 [default = 4];
    optional int32 keepdims = 2 [default = 1];
}

message VarianceParameter {
    repeated int32 dim = 1;
    optional bool keepdim = 2 [default = true];
}
message MeanParameter {
    repeated int32 dim = 1;
    optional bool keepdim = 2 [default = true];
}

// Message that stores parameters used by Interp3dLayer
message Interp3dParameter {
  optional int32 depth = 8 [default = 0]; // Depth of output
  optional int32 height = 1 [default = 0]; // Height of output
  optional int32 width = 2 [default = 0]; // Width of output
  optional int32 zoom_factor = 3 [default = 1]; // zoom factor
  optional int32 shrink_factor = 4 [default = 1]; // shrink factor
  optional int32 pad_beg = 5 [default = 0]; // padding at begin of input
  optional int32 pad_end = 6 [default = 0]; // padding at end of input
  optional bool  align_corners = 7 [default = true];
}
message GRUParameter {
  required int32 hidden_size = 1;
  optional bool bidirectional = 2 [default = false];
}

message CorrelationMigParameter {
  optional int32 shift_step = 1 [default = 9];
}

// Message that stores parameters used by ArgSortLayer
message ArgSortParameter {
  optional bool descending = 1 [default = false];
  optional int32 axis = 2;
}

// Message that stores parameters used by CumProdLayer
message CumProdParameter {
  optional int32 axis = 1;
}