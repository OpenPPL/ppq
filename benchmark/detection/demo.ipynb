{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      ____  ____  __   ____                    __              __\n",
      "     / __ \\/ __ \\/ /  / __ \\__  ______ _____  / /_____  ____  / /\n",
      "    / /_/ / /_/ / /  / / / / / / / __ `/ __ \\/ __/ __ \\/ __ \\/ /\n",
      "   / ____/ ____/ /__/ /_/ / /_/ / /_/ / / / / /_/ /_/ / /_/ / /\n",
      "  /_/   /_/   /_____\\___\\_\\__,_/\\__,_/_/ /_/\\__/\\____/\\____/_/\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ppq import *\n",
    "from ppq.api import *\n",
    "import torch\n",
    "import cfg\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 消除冗余算子\n",
    "# import onnx\n",
    "# from onnxsim import simplify\n",
    "\n",
    "# onnx_file = \"/home/geng/tinyml/ppq/benchmark/detection/FP32_model/Retinanet-FP32-end-11.onnx\"\n",
    "# onnx_model = onnx.load(onnx_file) \n",
    "# model_simp, check = simplify(onnx_model)   #对onnx模型进行简化，消除冗余算子        \n",
    "# assert check, \"Simplified ONNX model could not be validated\"\n",
    "# onnx.save(model_simp, onnx_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 升级模型\n",
    "import onnx\n",
    "from onnx import version_converter, helper\n",
    "\n",
    "# # Preprocessing: load the model to be converted.\n",
    "# model_path = \"/home/geng/tinyml/ppq/benchmark/detection/FP32_model/Retinanet-FP32.onnx\"\n",
    "# original_model = onnx.load(model_path)\n",
    "\n",
    "# # A full list of supported adapters can be found here:\n",
    "# # https://github.com/onnx/onnx/blob/main/onnx/version_converter.py#L21\n",
    "# # Apply the version conversion on the original model\n",
    "# converted_model = version_converter.convert_version(original_model, 11)\n",
    "\n",
    "# onnx.save(converted_model, \"/home/geng/tinyml/ppq/benchmark/detection/FP32_model/Retinanet-FP32.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.82s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/geng/tinyml/ppq/benchmark/detection/FP32_model/Retinanet-FP32.onnx\"\n",
    "# model_path = \"/home/geng/tinyml/ppq/benchmark/detection/FP32_model/end2end-12.onnx\"\n",
    "\n",
    "from dataset import build_dataset\n",
    "import torch\n",
    "import cfg\n",
    "\n",
    "model_name = \"Retinanet\"\n",
    "input_size = cfg.MODELS[model_name][\"INPUT_SHAPE\"]\n",
    "# 获取校准数据集\n",
    "_,calib_dataloader =  build_dataset(ann_file=cfg.ANN_PATH,data_root=cfg.DATA_ROOT,\n",
    "        input_size=input_size,batch_size=cfg.CALIBRATION_BATCH_SIZE)\n",
    "\n",
    "# calib_dataloader = [torch.rand(size=input_size) for _ in range(512)]\n",
    "\n",
    "\n",
    "config = cfg.PLATFORM_CONFIGS[\"TRT\"]\n",
    "config[\"QuanSetting\"].dispatcher = \"conservative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:29:18] PPQ Quantization Config Refine Pass Running ... Finished.\n",
      "[18:29:18] PPQ Quantization Fusion Pass Running ...        Finished.\n",
      "[18:29:19] PPQ Quantize Simplify Pass Running ...          Finished.\n",
      "[18:29:19] PPQ Parameter Quantization Pass Running ...     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1):   0%|          | 0/512 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "[18:29:19] PPQ Runtime Calibration Pass Running ...        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1):   0%|          | 1/512 [00:07<1:04:11,  7.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcad02/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ppq_quant_ir \u001b[39m=\u001b[39m quantize_onnx_model(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcad02/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     onnx_import_file\u001b[39m=\u001b[39;49mmodel_path, calib_dataloader\u001b[39m=\u001b[39;49mcalib_dataloader, calib_steps\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mCALIBRATION_NUM \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m cfg\u001b[39m.\u001b[39;49mCALIBRATION_BATCH_SIZE, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcad02/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     setting\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mQuanSetting\u001b[39;49m\u001b[39m\"\u001b[39;49m],input_shape\u001b[39m=\u001b[39;49minput_size, collate_fn\u001b[39m=\u001b[39;49m\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m\"\u001b[39;49m\u001b[39mimg\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mto(cfg\u001b[39m.\u001b[39;49mDEVICE), \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcad02/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     platform\u001b[39m=\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mQuantPlatform\u001b[39;49m\u001b[39m\"\u001b[39;49m], do_quantize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/core/defs.py:54\u001b[0m, in \u001b[0;36mempty_ppq_cache.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m empty_cache() \u001b[39m# torch.cuda.empty_cache might requires a sync of all cuda device.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m gc\u001b[39m.\u001b[39mcollect()  \u001b[39m# empty memory.\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/api/interface.py:284\u001b[0m, in \u001b[0;36mquantize_onnx_model\u001b[0;34m(onnx_import_file, calib_dataloader, calib_steps, input_shape, platform, input_dtype, inputs, setting, collate_fn, device, verbose, do_quantize)\u001b[0m\n\u001b[1;32m    282\u001b[0m executor \u001b[39m=\u001b[39m TorchExecutor(graph\u001b[39m=\u001b[39mquantizer\u001b[39m.\u001b[39m_graph, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m do_quantize:\n\u001b[0;32m--> 284\u001b[0m     quantizer\u001b[39m.\u001b[39;49mquantize(\n\u001b[1;32m    285\u001b[0m         inputs\u001b[39m=\u001b[39;49mdummy_input,\n\u001b[1;32m    286\u001b[0m         calib_dataloader\u001b[39m=\u001b[39;49mcalib_dataloader,\n\u001b[1;32m    287\u001b[0m         executor\u001b[39m=\u001b[39;49mexecutor,\n\u001b[1;32m    288\u001b[0m         setting\u001b[39m=\u001b[39;49msetting,\n\u001b[1;32m    289\u001b[0m         calib_steps\u001b[39m=\u001b[39;49mcalib_steps,\n\u001b[1;32m    290\u001b[0m         collate_fn\u001b[39m=\u001b[39;49mcollate_fn\n\u001b[1;32m    291\u001b[0m     )\n\u001b[1;32m    292\u001b[0m     \u001b[39mif\u001b[39;00m verbose: quantizer\u001b[39m.\u001b[39mreport()\n\u001b[1;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m quantizer\u001b[39m.\u001b[39m_graph\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/core/defs.py:54\u001b[0m, in \u001b[0;36mempty_ppq_cache.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m empty_cache() \u001b[39m# torch.cuda.empty_cache might requires a sync of all cuda device.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m gc\u001b[39m.\u001b[39mcollect()  \u001b[39m# empty memory.\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/quantization/quantizer/base.py:66\u001b[0m, in \u001b[0;36mBaseQuantizer.quantize\u001b[0;34m(self, inputs, calib_dataloader, executor, setting, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m executor\u001b[39m.\u001b[39mload_graph(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph)\n\u001b[1;32m     64\u001b[0m quant_pipeline \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuild_quant_pipeline(setting)\n\u001b[0;32m---> 66\u001b[0m quant_pipeline\u001b[39m.\u001b[39;49moptimize(\n\u001b[1;32m     67\u001b[0m     graph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph,\n\u001b[1;32m     68\u001b[0m     dataloader\u001b[39m=\u001b[39;49mcalib_dataloader,\n\u001b[1;32m     69\u001b[0m     executor\u001b[39m=\u001b[39;49mexecutor,\n\u001b[1;32m     70\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_verbose,\n\u001b[1;32m     71\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     72\u001b[0m )\n\u001b[1;32m     74\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verbose:\n\u001b[1;32m     75\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreport(), end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/quantization/optim/base.py:97\u001b[0m, in \u001b[0;36mQuantizationOptimizationPipeline.optimize\u001b[0;34m(self, graph, dataloader, executor, verbose, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(graph, BaseGraph): \n\u001b[1;32m     95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mparameter 1 should be an instance of PPQ BaseGraph when calling optim pass, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     96\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhowever \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(graph)\u001b[39m}\u001b[39;00m\u001b[39m was given.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 97\u001b[0m optim_pass\u001b[39m.\u001b[39;49mapply(graph\u001b[39m=\u001b[39;49mgraph, dataloader\u001b[39m=\u001b[39;49mdataloader, executor\u001b[39m=\u001b[39;49mexecutor, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m verbose: \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFinished.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/quantization/optim/base.py:31\u001b[0m, in \u001b[0;36mQuantizationOptimizationPass.apply\u001b[0;34m(self, graph, dataloader, executor, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(graph, BaseGraph):\n\u001b[1;32m     28\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     29\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mIncorrect graph object input, expect PPQ BaseGraph here, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mwhile \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(graph)\u001b[39m}\u001b[39;00m\u001b[39m was given.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimize(graph, dataloader\u001b[39m=\u001b[39;49mdataloader, executor\u001b[39m=\u001b[39;49mexecutor, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/core/defs.py:54\u001b[0m, in \u001b[0;36mempty_ppq_cache.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m empty_cache() \u001b[39m# torch.cuda.empty_cache might requires a sync of all cuda device.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m gc\u001b[39m.\u001b[39mcollect()  \u001b[39m# empty memory.\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/quantization/optim/calibration.py:181\u001b[0m, in \u001b[0;36mRuntimeCalibrationPass.optimize\u001b[0;34m(self, graph, dataloader, executor, calib_steps, collate_fn, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m     hooks[op_name]           \u001b[39m=\u001b[39m observer\u001b[39m.\u001b[39mhook\n\u001b[1;32m    179\u001b[0m \u001b[39m# ready for calibration\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[39m# hook forward function, let observers take effects.\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalibrate(desc\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mCalibration Progress(Phase 1)\u001b[39;49m\u001b[39m'\u001b[39;49m, dataloader\u001b[39m=\u001b[39;49mdataloader,\n\u001b[1;32m    182\u001b[0m     executor\u001b[39m=\u001b[39;49mexecutor, hooks\u001b[39m=\u001b[39;49mhooks, output_names\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    184\u001b[0m \u001b[39m# render calibration result.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mfor\u001b[39;00m _, observer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_observers\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/quantization/optim/calibration.py:123\u001b[0m, in \u001b[0;36mRuntimeCalibrationPass.calibrate\u001b[0;34m(self, desc, dataloader, executor, hooks, output_names)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collate_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_collate_fn(data)\n\u001b[0;32m--> 123\u001b[0m executor\u001b[39m.\u001b[39;49mforward(inputs\u001b[39m=\u001b[39;49mdata, hooks\u001b[39m=\u001b[39;49mhooks,\n\u001b[1;32m    124\u001b[0m     output_names\u001b[39m=\u001b[39;49moutput_names)\n\u001b[1;32m    125\u001b[0m progressing_bar\u001b[39m.\u001b[39mupdate()\n\u001b[1;32m    126\u001b[0m calib_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/executor/torch.py:240\u001b[0m, in \u001b[0;36mTorchExecutor.forward\u001b[0;34m(self, inputs, output_names, hooks)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m@\u001b[39m torch\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     hooks: Dict[\u001b[39mstr\u001b[39m, RuntimeHook] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Forward function of this executor.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[39m    Notice this forward function will never store and compute gradients.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39m        List[torch.Tensor]: [executing result, list of tensor objects.]\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__forward(\n\u001b[1;32m    241\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    242\u001b[0m         output_names\u001b[39m=\u001b[39;49moutput_names,\n\u001b[1;32m    243\u001b[0m         executing_order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executing_order,\n\u001b[1;32m    244\u001b[0m         hooks\u001b[39m=\u001b[39;49mhooks\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/executor/torch.py:371\u001b[0m, in \u001b[0;36mTorchExecutor.__forward\u001b[0;34m(self, inputs, executing_order, output_names, hooks)\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[39melse\u001b[39;00m: \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39minvalid hook instance was given with operation: \u001b[39m\u001b[39m{\u001b[39;00moperation\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    370\u001b[0m \u001b[39m# forward and collecting result\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m outputs \u001b[39m=\u001b[39m operation_forward_func(operation, inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executing_context)\n\u001b[1;32m    372\u001b[0m outputs \u001b[39m=\u001b[39m outputs \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39melse\u001b[39;00m [outputs]\n\u001b[1;32m    373\u001b[0m fp_outputs \u001b[39m=\u001b[39m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/executor/op/torch/default.py:1623\u001b[0m, in \u001b[0;36mTopK_forward\u001b[0;34m(op, values, ctx, **kwargs)\u001b[0m\n\u001b[1;32m   1621\u001b[0m k \u001b[39m=\u001b[39m convert_any_to_python_primary_type(k)\n\u001b[1;32m   1622\u001b[0m values, indices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtopk(\u001b[39minput\u001b[39m\u001b[39m=\u001b[39mx, k\u001b[39m=\u001b[39mk, dim\u001b[39m=\u001b[39maxis, largest\u001b[39m=\u001b[39mlargest, \u001b[39msorted\u001b[39m\u001b[39m=\u001b[39m\u001b[39msorted\u001b[39m)\n\u001b[0;32m-> 1623\u001b[0m \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39;49mto(\u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m), indices\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ppq_quant_ir = quantize_onnx_model(\n",
    "    onnx_import_file=model_path, calib_dataloader=calib_dataloader, calib_steps=8 // cfg.CALIBRATION_BATCH_SIZE, \n",
    "    setting=config[\"QuanSetting\"],input_shape=input_size, collate_fn=lambda x: x[\"img\"][0].to(cfg.DEVICE), \n",
    "    platform=config[\"QuantPlatform\"], do_quantize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error happens when dealing with operation Conv_37(TargetPlatform.TRT_INT8) - inputs:['input', 'onnx::Conv_1245', 'onnx::Conv_1246'], outputs:['input.3']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/executor/torch.py:371\u001b[0m, in \u001b[0;36mTorchExecutor.__forward\u001b[0;34m(self, inputs, executing_order, output_names, hooks)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39m# forward and collecting result\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m outputs \u001b[39m=\u001b[39m operation_forward_func(operation, inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executing_context)\n\u001b[1;32m    372\u001b[0m outputs \u001b[39m=\u001b[39m outputs \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(outputs, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)) \u001b[39melse\u001b[39;00m [outputs]\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/executor/op/torch/default.py:215\u001b[0m, in \u001b[0;36mConv_forward\u001b[0;34m(op, values, ctx, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m             onnx_pads \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 215\u001b[0m     output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mconv2d(\n\u001b[1;32m    216\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mx, weight\u001b[39m=\u001b[39;49mw, bias\u001b[39m=\u001b[39;49mb, groups\u001b[39m=\u001b[39;49mgroups, padding\u001b[39m=\u001b[39;49monnx_pads,\n\u001b[1;32m    217\u001b[0m         dilation\u001b[39m=\u001b[39;49mdilation, stride\u001b[39m=\u001b[39;49mstride)\n\u001b[1;32m    219\u001b[0m \u001b[39m# conv - 3d\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_MAPPING_ERROR",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcad02/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minference\u001b[39;00m \u001b[39mimport\u001b[39;00m ppq_inference\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcad02/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m dataloader \u001b[39m=\u001b[39m [\u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(calib_dataloader))]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcad02/home/geng/tinyml/ppq/benchmark/detection/demo.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m outputs \u001b[39m=\u001b[39m ppq_inference(dataloader\u001b[39m=\u001b[39;49mdataloader,ppq_ir \u001b[39m=\u001b[39;49m ppq_quant_ir,device \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/core/defs.py:54\u001b[0m, in \u001b[0;36mempty_ppq_cache.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m empty_cache() \u001b[39m# torch.cuda.empty_cache might requires a sync of all cuda device.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m gc\u001b[39m.\u001b[39mcollect()  \u001b[39m# empty memory.\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/tinyml/ppq/benchmark/detection/inference/detection_inference.py:15\u001b[0m, in \u001b[0;36mppq_inference\u001b[0;34m(dataloader, ppq_ir, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m executor \u001b[39m=\u001b[39m TorchExecutor(graph\u001b[39m=\u001b[39mppq_ir, device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     14\u001b[0m model_forward_function \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m input_tensor: executor(\u001b[39m*\u001b[39m[input_tensor])\n\u001b[0;32m---> 15\u001b[0m \u001b[39mreturn\u001b[39;00m _inference_any_module_with_coco(model_forward_function\u001b[39m=\u001b[39;49mmodel_forward_function,dataloader\u001b[39m=\u001b[39;49mdataloader,device\u001b[39m=\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/tinyml/ppq/benchmark/detection/inference/detection_inference.py:53\u001b[0m, in \u001b[0;36m_inference_any_module_with_coco\u001b[0;34m(model_forward_function, dataloader, device)\u001b[0m\n\u001b[1;32m     51\u001b[0m input_tensor \u001b[39m=\u001b[39m x[\u001b[39m\"\u001b[39m\u001b[39mimg\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     52\u001b[0m img_metas \u001b[39m=\u001b[39m x[\u001b[39m\"\u001b[39m\u001b[39mimg_metas\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdata[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m---> 53\u001b[0m output \u001b[39m=\u001b[39m model_forward_function(input_tensor)\n\u001b[1;32m     54\u001b[0m img_metas[\u001b[39m\"\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m output\n\u001b[1;32m     55\u001b[0m outputs\u001b[39m.\u001b[39mappend(img_metas)\n",
      "File \u001b[0;32m~/tinyml/ppq/benchmark/detection/inference/detection_inference.py:14\u001b[0m, in \u001b[0;36mppq_inference.<locals>.<lambda>\u001b[0;34m(input_tensor)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m@\u001b[39m empty_ppq_cache\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mppq_inference\u001b[39m(dataloader,ppq_ir,device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     13\u001b[0m     executor \u001b[39m=\u001b[39m TorchExecutor(graph\u001b[39m=\u001b[39mppq_ir, device\u001b[39m=\u001b[39mdevice)\n\u001b[0;32m---> 14\u001b[0m     model_forward_function \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m input_tensor: executor(\u001b[39m*\u001b[39;49m[input_tensor])\n\u001b[1;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m _inference_any_module_with_coco(model_forward_function\u001b[39m=\u001b[39mmodel_forward_function,dataloader\u001b[39m=\u001b[39mdataloader,device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/executor/base.py:195\u001b[0m, in \u001b[0;36mBaseGraphExecutor.__call__\u001b[0;34m(self, inputs, output_names)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    191\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    192\u001b[0m     inputs: Union[\u001b[39mdict\u001b[39m, torch\u001b[39m.\u001b[39mTensor],\n\u001b[1;32m    193\u001b[0m     output_names:List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    194\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(inputs\u001b[39m=\u001b[39;49minputs, output_names\u001b[39m=\u001b[39;49moutput_names)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/executor/torch.py:240\u001b[0m, in \u001b[0;36mTorchExecutor.forward\u001b[0;34m(self, inputs, output_names, hooks)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m@\u001b[39m torch\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     hooks: Dict[\u001b[39mstr\u001b[39m, RuntimeHook] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    206\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Forward function of this executor.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[39m    Notice this forward function will never store and compute gradients.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39m        List[torch.Tensor]: [executing result, list of tensor objects.]\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__forward(\n\u001b[1;32m    241\u001b[0m         inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[1;32m    242\u001b[0m         output_names\u001b[39m=\u001b[39;49moutput_names,\n\u001b[1;32m    243\u001b[0m         executing_order\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executing_order,\n\u001b[1;32m    244\u001b[0m         hooks\u001b[39m=\u001b[39;49mhooks\n\u001b[1;32m    245\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ppq/lib/python3.8/site-packages/ppq-0.6.5.1-py3.8.egg/ppq/executor/torch.py:398\u001b[0m, in \u001b[0;36mTorchExecutor.__forward\u001b[0;34m(self, inputs, executing_order, output_names, hooks)\u001b[0m\n\u001b[1;32m    396\u001b[0m             result_collector[output_names\u001b[39m.\u001b[39mindex(output_var\u001b[39m.\u001b[39mname)] \u001b[39m=\u001b[39m outputs[output_idx]\n\u001b[1;32m    397\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m _:\n\u001b[0;32m--> 398\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mError happens when dealing with operation \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(operation)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    400\u001b[0m \u001b[39m# remove useless value(runtime clear).\u001b[39;00m\n\u001b[1;32m    401\u001b[0m visited_op\u001b[39m.\u001b[39mappend(operation)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error happens when dealing with operation Conv_37(TargetPlatform.TRT_INT8) - inputs:['input', 'onnx::Conv_1245', 'onnx::Conv_1246'], outputs:['input.3']"
     ]
    }
   ],
   "source": [
    "from inference import ppq_inference\n",
    "dataloader = [next(iter(calib_dataloader))]\n",
    "outputs = ppq_inference(dataloader=dataloader,ppq_ir = ppq_quant_ir,device = \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process(model_type,outputs,class_num):\n",
    "    \"\"\"\n",
    "    将任意模型的输出转换为常规输出\n",
    "    [N,result]  N为样本数\n",
    "    result: [C,[M,5]] 其中C为类别,M为bbox数目，5为左上角、右下角坐标与置信分数。\n",
    "    并且根据尺度进行复原\n",
    "    \"\"\"\n",
    "    if model_type == \"Retinanet\":\n",
    "        print(\"deal with outputs in Retinanet type\")\n",
    "        results = []\n",
    "        for output in outputs:\n",
    "            img_scale = output[\"scale_factor\"] \n",
    "            labels,bboxs = output[\"output\"]\n",
    "            result = [[] for _ in range(class_num)]\n",
    "            if len(labels.shape) > 2:\n",
    "                # labels 和 bbox的输出顺序发生错换，需要调整\n",
    "                bboxs,labels = labels,bboxs\n",
    "                \n",
    "            bboxs,labels = bboxs[0],labels[0]\n",
    "            for i,label in enumerate(labels):\n",
    "                bboxs[i][:4] = bboxs[i][:4] / img_scale  # 进行bbox的尺寸复原\n",
    "                result[label].append(bboxs[i])\n",
    "            results.append(result)\n",
    "        return results\n",
    "    elif model_type == \"fasterrcnn\":\n",
    "        # TODO\n",
    "        pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deal with outputs in Retinanet type\n"
     ]
    }
   ],
   "source": [
    "results = post_process(model_name,outputs,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[tensor([390.2247,  69.4758, 496.9633, 349.0060,   0.9082]),\n",
       "   tensor([  0.0000, 263.6881,  62.3369, 308.3753,   0.4631]),\n",
       "   tensor([7.3020e-01, 2.2863e+02, 6.4735e+01, 3.0202e+02, 1.8964e-01])],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [tensor([4.2743e+02, 1.1253e+02, 4.6965e+02, 1.8548e+02, 2.4914e-01]),\n",
       "   tensor([4.0464e+02, 1.1265e+02, 4.6886e+02, 2.0723e+02, 2.3408e-01])],\n",
       "  [],\n",
       "  [tensor([4.1010e+02, 1.1412e+02, 4.6897e+02, 2.1819e+02, 3.2612e-01]),\n",
       "   tensor([4.2743e+02, 1.1253e+02, 4.6965e+02, 1.8548e+02, 2.6462e-01]),\n",
       "   tensor([3.9832e+02, 1.1009e+02, 4.7333e+02, 2.8062e+02, 2.5229e-01]),\n",
       "   tensor([3.5515e+02, 1.9895e+02, 3.9580e+02, 2.9157e+02, 1.8748e-01])],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [tensor([130.5934, 104.4944, 141.5827, 133.0618,   0.2439]),\n",
       "   tensor([3.8818e+02, 2.9966e+01, 4.1541e+02, 1.3671e+02, 2.1871e-01]),\n",
       "   tensor([1.2066e+02, 2.7238e+02, 1.4672e+02, 3.0605e+02, 2.0431e-01]),\n",
       "   tensor([3.8441e+02, 4.4563e+01, 3.9842e+02, 9.2133e+01, 2.0102e-01]),\n",
       "   tensor([2.1725e+02, 2.3488e+02, 2.5530e+02, 2.9772e+02, 1.5968e-01])],\n",
       "  [],\n",
       "  [tensor([120.6568, 272.3843, 146.7164, 306.0455,   0.3856]),\n",
       "   tensor([143.6788, 268.7132, 172.9991, 302.6072,   0.3027]),\n",
       "   tensor([156.0857, 113.3088, 174.4926, 129.4469,   0.2235]),\n",
       "   tensor([1.2077e+02, 2.7240e+02, 1.3806e+02, 2.9215e+02, 2.0187e-01]),\n",
       "   tensor([3.2240e+02, 1.6177e+02, 3.7251e+02, 2.0609e+02, 1.5891e-01])],\n",
       "  [tensor([9.1066e+01, 3.6635e+02, 1.2085e+02, 3.8880e+02, 2.1703e-01]),\n",
       "   tensor([5.1056e+02, 4.0767e+01, 5.2274e+02, 9.3778e+01, 1.6301e-01])],\n",
       "  [tensor([1.3533e+02, 2.4923e+02, 1.5387e+02, 2.7324e+02, 2.4867e-01]),\n",
       "   tensor([9.1996e+01, 3.6523e+02, 1.2450e+02, 3.8900e+02, 2.4412e-01]),\n",
       "   tensor([2.1597e+02, 2.3006e+02, 2.3915e+02, 2.8506e+02, 2.1796e-01]),\n",
       "   tensor([2.1456e+02, 2.3683e+02, 2.6706e+02, 2.9430e+02, 1.9830e-01]),\n",
       "   tensor([4.8895e+02, 4.4418e+01, 4.9836e+02, 9.0914e+01, 1.7625e-01]),\n",
       "   tensor([2.1467e+02, 2.4528e+02, 2.7162e+02, 2.7496e+02, 1.6844e-01])],\n",
       "  [tensor([ 89.1894,   6.8300, 140.4004, 110.5287,   0.4222]),\n",
       "   tensor([9.1195e+01, 3.6629e+02, 1.2031e+02, 3.8917e+02, 3.7836e-01]),\n",
       "   tensor([135.3271, 249.2283, 153.8667, 273.2392,   0.3056]),\n",
       "   tensor([100.0844,  41.1473, 137.1964, 103.5292,   0.3022]),\n",
       "   tensor([5.1076e+02, 4.3063e+01, 5.2258e+02, 9.3593e+01, 3.0133e-01]),\n",
       "   tensor([5.1218e+02, 3.8585e+01, 5.3112e+02, 1.1667e+02, 2.8024e-01]),\n",
       "   tensor([5.3071e+02, 4.1287e+01, 5.4837e+02, 1.2525e+02, 2.7379e-01]),\n",
       "   tensor([5.2270e+02, 3.9460e+01, 5.3856e+02, 1.1858e+02, 2.7325e-01]),\n",
       "   tensor([4.8405e+02, 4.2545e+01, 5.0872e+02, 1.2283e+02, 2.6623e-01]),\n",
       "   tensor([5.1946e+02, 7.3992e+01, 5.3229e+02, 1.1058e+02, 2.5842e-01]),\n",
       "   tensor([4.8851e+02, 4.4218e+01, 4.9877e+02, 9.3717e+01, 2.5534e-01]),\n",
       "   tensor([5.2828e+02, 4.7450e+01, 5.3995e+02, 1.0921e+02, 2.4550e-01]),\n",
       "   tensor([ 60.2071,  17.2758, 123.7740, 129.2444,   0.2379]),\n",
       "   tensor([5.3473e+02, 4.5104e+01, 5.4528e+02, 1.0954e+02, 2.3060e-01]),\n",
       "   tensor([5.3555e+02, 4.4281e+01, 5.5597e+02, 1.2716e+02, 2.1925e-01]),\n",
       "   tensor([ 61.8258,  17.9684, 114.7416,  78.8677,   0.2061]),\n",
       "   tensor([133.8507,   5.0561, 181.9156,  85.8987,   0.2061]),\n",
       "   tensor([4.8097e+02, 4.3488e+01, 5.0124e+02, 1.0450e+02, 2.0553e-01]),\n",
       "   tensor([1.1959e+02, 3.1981e+02, 1.6685e+02, 3.4588e+02, 1.9760e-01]),\n",
       "   tensor([4.9656e+02, 4.3851e+01, 5.1168e+02, 1.0845e+02, 1.7911e-01]),\n",
       "   tensor([1.3795e+02, 2.5046e+02, 1.6715e+02, 2.7326e+02, 1.7527e-01]),\n",
       "   tensor([1.3698e+02, 3.2843e+02, 1.6810e+02, 3.4843e+02, 1.7490e-01]),\n",
       "   tensor([5.1204e+02, 6.7413e+01, 5.2213e+02, 9.1189e+01, 1.7055e-01]),\n",
       "   tensor([2.1719e+02, 2.2829e+02, 2.4054e+02, 2.6913e+02, 1.6593e-01]),\n",
       "   tensor([5.2026e+02, 4.4059e+01, 5.3280e+02, 1.1220e+02, 1.6523e-01]),\n",
       "   tensor([1.9262e+02, 8.7405e+01, 2.1595e+02, 1.2971e+02, 1.6385e-01]),\n",
       "   tensor([62.0763, 21.3316, 93.4280, 71.8668,  0.1619]),\n",
       "   tensor([4.8318e+02, 4.3922e+01, 4.9319e+02, 9.2543e+01, 1.6099e-01]),\n",
       "   tensor([5.0682e+02, 2.4243e+01, 5.2754e+02, 1.0241e+02, 1.6053e-01])],\n",
       "  [tensor([154.7092, 168.3888, 183.6653, 184.5569,   0.6816]),\n",
       "   tensor([ 30.7631, 343.0311,  99.9520, 385.1058,   0.6355]),\n",
       "   tensor([ 56.9950, 287.7975, 135.4259, 328.2407,   0.5881]),\n",
       "   tensor([  9.2882, 334.4268,  90.5439, 377.0400,   0.4959]),\n",
       "   tensor([  0.0000, 315.9614,  81.3065, 368.7704,   0.4415]),\n",
       "   tensor([3.5858e+02, 6.3474e+01, 3.8112e+02, 8.5973e+01, 3.3223e-01]),\n",
       "   tensor([1.1696e+02, 3.1054e+02, 1.6859e+02, 3.4491e+02, 2.8931e-01]),\n",
       "   tensor([155.4239, 113.3279, 174.3624, 129.4743,   0.2810]),\n",
       "   tensor([2.5443e+02, 2.6295e+02, 2.9369e+02, 2.8152e+02, 2.5816e-01]),\n",
       "   tensor([8.0855e+01, 2.9445e+02, 1.4844e+02, 3.3599e+02, 2.4559e-01]),\n",
       "   tensor([ 60.1548,  16.4824, 123.5142, 129.8214,   0.2431]),\n",
       "   tensor([156.7713, 156.1007, 182.1033, 170.0373,   0.2268]),\n",
       "   tensor([1.1891e+02, 3.2080e+02, 1.5395e+02, 3.4409e+02, 2.1982e-01]),\n",
       "   tensor([1.9360e+02, 1.0694e+02, 2.1560e+02, 1.2910e+02, 2.1252e-01]),\n",
       "   tensor([134.8298,   4.2328, 182.7290,  76.9156,   0.2122]),\n",
       "   tensor([155.5785, 176.0029, 181.8270, 188.5470,   0.2035]),\n",
       "   tensor([1.4255e+02, 2.6775e+02, 1.7332e+02, 3.0257e+02, 1.9615e-01]),\n",
       "   tensor([132.9894,  33.9476, 169.8325, 105.9701,   0.1776]),\n",
       "   tensor([3.1927e+02, 1.6118e+02, 3.7305e+02, 2.0609e+02, 1.7219e-01]),\n",
       "   tensor([1.8126e+02, 1.4607e+02, 1.9333e+02, 1.8106e+02, 1.7064e-01]),\n",
       "   tensor([ 89.3115,   6.4381, 141.4636, 112.5063,   0.1631]),\n",
       "   tensor([1.5040e+02, 1.5971e+02, 1.8513e+02, 1.8776e+02, 1.6203e-01])],\n",
       "  [tensor([  0.0000,   0.3735,  57.9512, 148.8580,   0.2793])],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [tensor([5.7777e+01, 2.8859e+02, 1.3539e+02, 3.2813e+02, 1.9081e-01])],\n",
       "  [tensor([3.1678e+02, 1.1581e+02, 3.6299e+02, 1.4980e+02, 3.4994e-01]),\n",
       "   tensor([3.5772e+02, 9.8776e+01, 3.9702e+02, 1.4354e+02, 2.3229e-01]),\n",
       "   tensor([2.9983e+02, 1.5301e+02, 3.3954e+02, 1.8103e+02, 2.0550e-01])],\n",
       "  [tensor([0.0000e+00, 3.0860e+02, 8.2764e+01, 3.6800e+02, 3.4603e-01]),\n",
       "   tensor([1.2223e+01, 3.0756e+02, 4.9339e+01, 3.2488e+02, 2.0527e-01]),\n",
       "   tensor([3.1691e+02, 1.1567e+02, 3.6227e+02, 1.4944e+02, 1.9227e-01]),\n",
       "   tensor([2.5411e+02, 2.6322e+02, 2.9335e+02, 2.8198e+02, 1.6387e-01])],\n",
       "  [],\n",
       "  [],\n",
       "  [tensor([1.5451e+02, 1.0269e+02, 1.7483e+02, 1.2963e+02, 1.6536e-01])],\n",
       "  [],\n",
       "  [tensor([2.7686e+00, 2.2908e+02, 3.4809e+02, 4.2566e+02, 1.9493e-01])],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [tensor([4.8770e+02, 2.0584e+02, 6.1751e+02, 3.4101e+02, 4.7042e-01]),\n",
       "   tensor([0.0000e+00, 2.2870e+02, 3.4893e+02, 4.2565e+02, 3.3329e-01]),\n",
       "   tensor([1.3894e+02, 1.9494e+02, 3.6557e+02, 3.7905e+02, 2.4166e-01]),\n",
       "   tensor([2.3549e+02, 1.8454e+02, 3.7853e+02, 2.4141e+02, 2.1171e-01]),\n",
       "   tensor([2.0974e+02, 1.5927e+02, 3.9360e+02, 3.5043e+02, 2.0250e-01]),\n",
       "   tensor([1.5636e+00, 1.7285e+02, 1.9496e+02, 2.8541e+02, 1.9477e-01]),\n",
       "   tensor([1.8288e+02, 2.2553e+02, 3.5340e+02, 3.3299e+02, 1.7418e-01]),\n",
       "   tensor([1.9976e+02, 1.5207e+02, 3.6794e+02, 2.3968e+02, 1.6653e-01])],\n",
       "  [],\n",
       "  [tensor([4.9646e+02, 2.0259e+02, 6.0083e+02, 2.2758e+02, 3.5667e-01]),\n",
       "   tensor([5.0385e+02, 2.0878e+02, 5.7721e+02, 2.2357e+02, 1.6091e-01])],\n",
       "  [],\n",
       "  [],\n",
       "  [tensor([5.6167e+02, 3.9722e+01, 6.1391e+02, 1.1016e+02, 2.0739e-01])],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  [],\n",
       "  []]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Retinanet\"\n",
    "export_ppq_graph(   graph = ppq_quant_ir,\n",
    "                    platform=TargetPlatform.ONNXRUNTIME,\n",
    "                    graph_save_to=f'{os.path.join(config[\"OutputPath\"], model_name)}-ORT-END-INT8.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(calib_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 800, 1216])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[\"img\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 3, 800, 1216)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calib_input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "op Less need opset (12,16)\n",
    "op TopK need opset (1,12)\n",
    "Upsample not supported\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ppq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1f49b93815805eca9ccc5299d655a62f3a8d0678e274dc3dfeb518f21176dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
