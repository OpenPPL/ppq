{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对分类模型进行量化，并测试精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      ____  ____  __   ____                    __              __\n",
      "     / __ \\/ __ \\/ /  / __ \\__  ______ _____  / /_____  ____  / /\n",
      "    / /_/ / /_/ / /  / / / / / / / __ `/ __ \\/ __/ __ \\/ __ \\/ /\n",
      "   / ____/ ____/ /__/ /_/ / /_/ / /_/ / / / / /_/ /_/ / /_/ / /\n",
      "  /_/   /_/   /_____\\___\\_\\__,_/\\__,_/_/ /_/\\__/\\____/\\____/_/\n",
      "\n",
      "\n",
      "\u001b[31mTensorRT is not installed, TRT Exporter is disabled.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from ppq import *\n",
    "from ppq.api import *\n",
    "from Utilities.Imagenet import (evaluate_mmlab_module_with_imagenet,\n",
    "                                evaluate_onnx_module_with_imagenet,\n",
    "                                evaluate_ppq_module_with_imagenet,\n",
    "                                evaluate_torch_module_with_imagenet,\n",
    "                                load_imagenet_from_directory)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试全精度模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_PLATFORM = TargetPlatform.OPENVINO_INT8   # 用来指定目标平台\n",
    "platform = \"OpenVino\"\n",
    "\n",
    "CFG_DEVICE = 'cuda'                            # 一个神奇的字符串，用来确定执行设备\n",
    "CFG_BATCHSIZE = 64                             # 测试与calib时的 batchsize\n",
    "CFG_INPUT_SHAPE = (CFG_BATCHSIZE, 3, 224, 224) # 用来确定模型输入的尺寸，好像 imagenet 都是这个尺寸\n",
    "CFG_VALIDATION_DIR = '/home/geng/tinyml/ppq/benchmark/Assets/Imagenet_Valid'   # 用来读取 validation dataset\n",
    "CFG_TRAIN_DIR = '/home/geng/tinyml/ppq/benchmark/Assets/Imagenet_Train'        # 用来读取 train dataset，注意该集合将被用来 calibrate 你的模型\n",
    "CFG_DUMP_PATH = '/home/geng/tinyml/ppq/benchmark/classification/'+platform+'_output'    # 所有模型保存的路径名\n",
    "QUANT_SETTING = QuantizationSettingFactory.default_setting() # 用来指定量化配置\n",
    "if not os.path.exists(CFG_DUMP_PATH):\n",
    "    os.makedirs(CFG_DUMP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|model|TargetPlatform|ORT FP32|PPQ INT8|DQD ORT INT8|RealPlatform INT8|\n",
    "|----|----|----|----|----|----|\n",
    "|resnet18|OpenVino|69.764|69.466|67.109|-|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPPQ is compling CUDA Kernels. Please wait...If there is any problem with kernel compilation, feel free to remove ENABLE_CUDA_KERNEL clause.\u001b[0m\n",
      "---------------------- PPQ Quantization Test Running with resnet18 ----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geng/anaconda3/envs/ppq/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/geng/anaconda3/envs/ppq/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Evaluating Model...:   0%|          | 0/781 [00:00<?, ?it/s]/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prec1, prec5 = accuracy(torch.tensor(batch_pred).to('cpu'), batch_label.to('cpu'), topk=(1, 5))\n",
      "Evaluating Model...:   0%|          | 3/781 [00:01<03:41,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0 / 781]\tPrec@1 84.375 (84.375)\tPrec@5 95.312 (95.312)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  13%|█▎        | 104/781 [00:05<00:35, 18.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100 / 781]\tPrec@1 76.269 (76.269)\tPrec@5 92.280 (92.280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  26%|██▌       | 203/781 [00:10<00:26, 21.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [200 / 781]\tPrec@1 75.793 (75.793)\tPrec@5 93.190 (93.190)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  39%|███▊      | 302/781 [00:15<00:20, 23.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [300 / 781]\tPrec@1 76.230 (76.230)\tPrec@5 93.490 (93.490)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  52%|█████▏    | 404/781 [00:20<00:17, 21.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [400 / 781]\tPrec@1 73.589 (73.589)\tPrec@5 91.732 (91.732)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  64%|██████▍   | 503/781 [00:24<00:11, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [500 / 781]\tPrec@1 72.040 (72.040)\tPrec@5 90.556 (90.556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  77%|███████▋  | 605/781 [00:29<00:07, 22.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [600 / 781]\tPrec@1 70.793 (70.793)\tPrec@5 89.757 (89.757)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  90%|█████████ | 704/781 [00:34<00:03, 23.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [700 / 781]\tPrec@1 69.824 (69.824)\tPrec@5 89.042 (89.042)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...: 100%|██████████| 781/781 [00:38<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 69.764 Prec@5 89.085\n",
      "[22:33:35] PPQ Quantization Config Refine Pass Running ... Finished.\n",
      "[22:33:35] PPQ Quantization Fusion Pass Running ...        Finished.\n",
      "[22:33:36] PPQ Quantize Point Reduce Pass Running ...      Finished.\n",
      "[22:33:36] PPQ Parameter Quantization Pass Running ...     \u001b[31mNumeric instability detected: ppq find there is a scale value < 1e-7, which probably cause numeric underflow in further computation.\u001b[0m\n",
      "\u001b[31mNumeric instability detected: ppq find there is a scale value < 1e-7, which probably cause numeric underflow in further computation.\u001b[0m\n",
      "\u001b[31mNumeric instability detected: ppq find there is a scale value < 1e-7, which probably cause numeric underflow in further computation.\u001b[0m\n",
      "\u001b[31mNumeric instability detected: ppq find there is a scale value < 1e-7, which probably cause numeric underflow in further computation.\u001b[0m\n",
      "\u001b[31mNumeric instability detected: ppq find there is a scale value < 1e-7, which probably cause numeric underflow in further computation.\u001b[0m\n",
      "\u001b[31mNumeric instability detected: ppq find there is a scale value < 1e-7, which probably cause numeric underflow in further computation.\u001b[0m\n",
      "\u001b[31mNumeric instability detected: ppq find there is a scale value < 1e-7, which probably cause numeric underflow in further computation.\u001b[0m\n",
      "\u001b[31mNumeric instability detected: ppq find there is a scale value < 1e-7, which probably cause numeric underflow in further computation.\u001b[0m\n",
      "Finished.\n",
      "[22:33:36] PPQ Runtime Calibration Pass Running ...        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1): 100%|██████████| 80/80 [00:07<00:00, 10.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "[22:33:44] PPQ Quantization Alignment Pass Running ...     Finished.\n",
      "[22:33:44] PPQ Passive Parameter Quantization Running ...  Finished.\n",
      "[22:33:44] PPQ Parameter Baking Pass Running ...           Finished.\n",
      "--------- Network Snapshot ---------\n",
      "Num of Op:                    [49]\n",
      "Num of Quantized Op:          [49]\n",
      "Num of Variable:              [92]\n",
      "Num of Quantized Var:         [92]\n",
      "------- Quantization Snapshot ------\n",
      "Num of Quant Config:          [148]\n",
      "BAKED:                        [21]\n",
      "OVERLAPPED:                   [57]\n",
      "SLAVE:                        [19]\n",
      "ACTIVATED:                    [30]\n",
      "PASSIVE_BAKED:                [21]\n",
      "Network Quantization Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:   0%|          | 0/781 [00:00<?, ?it/s]/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_forward_function = lambda input_tensor: torch.tensor(\n",
      "/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prec1, prec5 = accuracy(torch.tensor(batch_pred).to('cpu'), batch_label.to('cpu'), topk=(1, 5))\n",
      "Evaluating Model...:   0%|          | 2/781 [00:00<04:05,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0 / 781]\tPrec@1 84.375 (84.375)\tPrec@5 96.875 (96.875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  13%|█▎        | 103/781 [00:08<00:48, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100 / 781]\tPrec@1 75.820 (75.820)\tPrec@5 92.188 (92.188)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  26%|██▌       | 203/781 [00:15<00:42, 13.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [200 / 781]\tPrec@1 75.319 (75.319)\tPrec@5 93.113 (93.113)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  39%|███▉      | 303/781 [00:22<00:35, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [300 / 781]\tPrec@1 75.810 (75.810)\tPrec@5 93.366 (93.366)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  52%|█████▏    | 403/781 [00:30<00:27, 13.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [400 / 781]\tPrec@1 73.289 (73.289)\tPrec@5 91.619 (91.619)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  64%|██████▍   | 503/781 [00:37<00:20, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [500 / 781]\tPrec@1 71.744 (71.744)\tPrec@5 90.435 (90.435)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  77%|███████▋  | 603/781 [00:44<00:13, 13.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [600 / 781]\tPrec@1 70.435 (70.435)\tPrec@5 89.608 (89.608)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  90%|█████████ | 703/781 [00:51<00:05, 13.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [700 / 781]\tPrec@1 69.512 (69.512)\tPrec@5 88.902 (88.902)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...: 100%|██████████| 781/781 [00:57<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 69.466 Prec@5 88.934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geng/anaconda3/envs/ppq/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:55: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\"Specified provider '{}' is not in available provider names.\"\n",
      "Evaluating Model...:   0%|          | 0/781 [00:00<?, ?it/s]/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:107: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  model_forward_function = lambda input_tensor: torch.tensor(sess.run(\n",
      "/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prec1, prec5 = accuracy(torch.tensor(batch_pred).to('cpu'), batch_label.to('cpu'), topk=(1, 5))\n",
      "Evaluating Model...:   0%|          | 1/781 [00:01<20:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0 / 781]\tPrec@1 81.250 (81.250)\tPrec@5 93.750 (93.750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  13%|█▎        | 101/781 [01:00<06:12,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100 / 781]\tPrec@1 74.288 (74.288)\tPrec@5 91.290 (91.290)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  26%|██▌       | 201/781 [02:00<05:30,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [200 / 781]\tPrec@1 73.593 (73.593)\tPrec@5 92.211 (92.211)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  39%|███▊      | 301/781 [03:01<05:09,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [300 / 781]\tPrec@1 74.024 (74.024)\tPrec@5 92.333 (92.333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  51%|█████▏    | 401/781 [04:02<04:07,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [400 / 781]\tPrec@1 71.372 (71.372)\tPrec@5 90.395 (90.395)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  64%|██████▍   | 501/781 [05:01<03:07,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [500 / 781]\tPrec@1 69.673 (69.673)\tPrec@5 89.097 (89.097)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  77%|███████▋  | 601/781 [06:00<01:47,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [600 / 781]\tPrec@1 68.342 (68.342)\tPrec@5 88.150 (88.150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  90%|████████▉ | 701/781 [06:58<00:48,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [700 / 781]\tPrec@1 67.306 (67.306)\tPrec@5 87.357 (87.357)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...: 100%|██████████| 781/781 [07:43<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 67.109 Prec@5 87.246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with ENABLE_CUDA_KERNEL():\n",
    "    model_builder, model_name  = torchvision.models.resnet18, 'resnet18'\n",
    "\n",
    "    print(f'---------------------- PPQ Quantization Test Running with {model_name} ----------------------')\n",
    "    model = model_builder(pretrained=True).to(CFG_DEVICE)\n",
    "\n",
    "    #测试FP32精度\n",
    "    fp32_report = evaluate_torch_module_with_imagenet(\n",
    "        model=model, imagenet_validation_dir=CFG_VALIDATION_DIR,\n",
    "        batchsize=CFG_BATCHSIZE, device=CFG_DEVICE, verbose=True)\n",
    "\n",
    "    # 获取校准数据\n",
    "    dataloader = load_imagenet_from_directory(\n",
    "        directory=CFG_TRAIN_DIR, batchsize=CFG_BATCHSIZE,\n",
    "        shuffle=False, subset=5120, require_label=False,\n",
    "        num_of_workers=8)\n",
    "\n",
    "    # 量化torch模型\n",
    "    ppq_quant_ir = quantize_torch_model(\n",
    "        model=model, calib_dataloader=dataloader, input_shape=CFG_INPUT_SHAPE,\n",
    "        calib_steps=5120 // CFG_BATCHSIZE, collate_fn=lambda x: x.to(CFG_DEVICE), verbose=1,\n",
    "        device=CFG_DEVICE, platform=CFG_PLATFORM, setting=QUANT_SETTING,\n",
    "        onnx_export_file=f'{os.path.join(CFG_DUMP_PATH, model_name)}-FP32.onnx')\n",
    "        \n",
    "    # 评估PPQ量化后的模型\n",
    "    ppq_int8_report = evaluate_ppq_module_with_imagenet(\n",
    "        model=ppq_quant_ir, imagenet_validation_dir=CFG_VALIDATION_DIR,\n",
    "        batchsize=CFG_BATCHSIZE, device=CFG_DEVICE, verbose=True)\n",
    "\n",
    "    # 导出平台部署模型\n",
    "    export_ppq_graph(\n",
    "        graph=ppq_quant_ir, \n",
    "        platform=CFG_PLATFORM,\n",
    "        graph_save_to=f'{os.path.join(CFG_DUMP_PATH, model_name)}-INT8.onnx',\n",
    "        config_save_to=f'{os.path.join(CFG_DUMP_PATH, model_name)}-INT8.json' )\n",
    "    \n",
    "    # 评估onnx运行模型\n",
    "    evaluate_onnx_module_with_imagenet(\n",
    "        onnxruntime_model_path=f'{os.path.join(CFG_DUMP_PATH, model_name)}-INT8.onnx', \n",
    "        imagenet_validation_dir=CFG_VALIDATION_DIR, batchsize=CFG_BATCHSIZE, \n",
    "        device=CFG_DEVICE)\n",
    "\n",
    "    # ppq_int8_report.to_csv(f'{os.path.join(CFG_DUMP_PATH, model_name)}-report.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ppq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1f49b93815805eca9ccc5299d655a62f3a8d0678e274dc3dfeb518f21176dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
