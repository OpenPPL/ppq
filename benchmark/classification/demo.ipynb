{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对分类模型进行量化，并测试精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from ppq import *\n",
    "from ppq.api import *\n",
    "from Utilities.Imagenet import (evaluate_mmlab_module_with_imagenet,\n",
    "                                evaluate_onnx_module_with_imagenet,\n",
    "                                evaluate_ppq_module_with_imagenet,\n",
    "                                evaluate_torch_module_with_imagenet,\n",
    "                                load_imagenet_from_directory)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试全精度模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG_PLATFORM = TargetPlatform.TRT_INT8  # 用来指定目标平台\n",
    "platform = \"TRT\"  #记得修改上面两个\n",
    "QUANT_SETTING = QuantizationSettingFactory.trt_setting() # 用来指定量化配置\n",
    "\n",
    "CFG_DEVICE = 'cuda'                            # 一个神奇的字符串，用来确定执行设备\n",
    "CFG_BATCHSIZE = 64                             # 测试与calib时的 batchsize\n",
    "CFG_INPUT_SHAPE = (CFG_BATCHSIZE, 3, 224, 224) # 用来确定模型输入的尺寸，好像 imagenet 都是这个尺寸\n",
    "CFG_VALIDATION_DIR = '/home/geng/tinyml/ppq/benchmark/Assets/Imagenet_Valid'   # 用来读取 validation dataset\n",
    "CFG_TRAIN_DIR = '/home/geng/tinyml/ppq/benchmark/Assets/Imagenet_Train'        # 用来读取 train dataset，注意该集合将被用来 calibrate 你的模型\n",
    "CFG_DUMP_PATH = '/home/geng/tinyml/ppq/benchmark/classification/'+platform+'_output'    # 所有模型保存的路径名\n",
    "\n",
    "if not os.path.exists(CFG_DUMP_PATH):\n",
    "    os.makedirs(CFG_DUMP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|model|TargetPlatform|ORT FP32|PPQ INT8|DQD ORT INT8|RealPlatform INT8|\n",
    "|----|----|----|----|----|----|\n",
    "|resnet18|OpenVino|69.764|69.466|67.109|-|\n",
    "|resnet18|TRT|69.764|69.548|69.524|-|\n",
    "|resnet18|Snpe|69.764|69.278|69.266|-|\n",
    "|resnet18|Ncnn|69.764|69.106|69.070|-|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mPPQ is compling CUDA Kernels. Please wait...If there is any problem with kernel compilation, feel free to remove ENABLE_CUDA_KERNEL clause.\u001b[0m\n",
      "---------------------- PPQ Quantization Test Running with resnet18 ----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geng/anaconda3/envs/ppq/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/geng/anaconda3/envs/ppq/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Evaluating Model...:   0%|          | 0/781 [00:00<?, ?it/s]/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prec1, prec5 = accuracy(torch.tensor(batch_pred).to('cpu'), batch_label.to('cpu'), topk=(1, 5))\n",
      "Evaluating Model...:   0%|          | 1/781 [00:00<08:21,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0 / 781]\tPrec@1 84.375 (84.375)\tPrec@5 95.312 (95.312)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  13%|█▎        | 104/781 [00:05<00:31, 21.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100 / 781]\tPrec@1 76.269 (76.269)\tPrec@5 92.280 (92.280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  26%|██▌       | 203/781 [00:10<00:24, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [200 / 781]\tPrec@1 75.793 (75.793)\tPrec@5 93.190 (93.190)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  39%|███▊      | 302/781 [00:15<00:20, 23.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [300 / 781]\tPrec@1 76.230 (76.230)\tPrec@5 93.490 (93.490)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  52%|█████▏    | 404/781 [00:20<00:16, 22.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [400 / 781]\tPrec@1 73.589 (73.589)\tPrec@5 91.732 (91.732)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  65%|██████▍   | 506/781 [00:24<00:11, 24.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [500 / 781]\tPrec@1 72.040 (72.040)\tPrec@5 90.556 (90.556)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  77%|███████▋  | 605/781 [00:29<00:07, 22.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [600 / 781]\tPrec@1 70.793 (70.793)\tPrec@5 89.757 (89.757)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  90%|█████████ | 704/781 [00:33<00:03, 20.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [700 / 781]\tPrec@1 69.824 (69.824)\tPrec@5 89.042 (89.042)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...: 100%|██████████| 781/781 [00:37<00:00, 20.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 69.764 Prec@5 89.085\n",
      "[07:45:02] PPQ Quantization Config Refine Pass Running ... Finished.\n",
      "[07:45:02] PPQ Quantization Fusion Pass Running ...        Finished.\n",
      "[07:45:02] PPQ Quantize Point Reduce Pass Running ...      Finished.\n",
      "[07:45:02] PPQ Parameter Quantization Pass Running ...     Finished.\n",
      "[07:45:02] PPQ Runtime Calibration Pass Running ...        "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1): 100%|██████████| 80/80 [00:07<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "[07:45:10] PPQ Quantization Alignment Pass Running ...     Finished.\n",
      "[07:45:10] PPQ Passive Parameter Quantization Running ...  Finished.\n",
      "[07:45:10] PPQ Parameter Baking Pass Running ...           Finished.\n",
      "--------- Network Snapshot ---------\n",
      "Num of Op:                    [49]\n",
      "Num of Quantized Op:          [47]\n",
      "Num of Variable:              [92]\n",
      "Num of Quantized Var:         [88]\n",
      "------- Quantization Snapshot ------\n",
      "Num of Quant Config:          [142]\n",
      "BAKED:                        [20]\n",
      "OVERLAPPED:                   [56]\n",
      "SLAVE:                        [19]\n",
      "ACTIVATED:                    [27]\n",
      "PASSIVE_BAKED:                [20]\n",
      "Network Quantization Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:   0%|          | 0/781 [00:00<?, ?it/s]/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:143: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  model_forward_function = lambda input_tensor: torch.tensor(\n",
      "/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prec1, prec5 = accuracy(torch.tensor(batch_pred).to('cpu'), batch_label.to('cpu'), topk=(1, 5))\n",
      "Evaluating Model...:   0%|          | 1/781 [00:00<11:45,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0 / 781]\tPrec@1 85.938 (85.938)\tPrec@5 93.750 (93.750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  13%|█▎        | 103/781 [00:08<00:48, 14.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100 / 781]\tPrec@1 75.541 (75.541)\tPrec@5 92.126 (92.126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  26%|██▌       | 203/781 [00:15<00:41, 14.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [200 / 781]\tPrec@1 75.241 (75.241)\tPrec@5 93.074 (93.074)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  39%|███▉      | 303/781 [00:22<00:33, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [300 / 781]\tPrec@1 75.903 (75.903)\tPrec@5 93.350 (93.350)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  52%|█████▏    | 403/781 [00:29<00:26, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [400 / 781]\tPrec@1 73.231 (73.231)\tPrec@5 91.650 (91.650)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  64%|██████▍   | 503/781 [00:36<00:19, 14.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [500 / 781]\tPrec@1 71.597 (71.597)\tPrec@5 90.472 (90.472)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  77%|███████▋  | 603/781 [00:43<00:12, 13.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [600 / 781]\tPrec@1 70.289 (70.289)\tPrec@5 89.624 (89.624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  90%|█████████ | 703/781 [00:51<00:05, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [700 / 781]\tPrec@1 69.318 (69.318)\tPrec@5 88.880 (88.880)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...: 100%|██████████| 781/781 [00:56<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 69.278 Prec@5 88.936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/geng/anaconda3/envs/ppq/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:55: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CPUExecutionProvider'\n",
      "  warnings.warn(\"Specified provider '{}' is not in available provider names.\"\n",
      "Evaluating Model...:   0%|          | 0/781 [00:00<?, ?it/s]/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:188: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prec1, prec5 = accuracy(torch.tensor(batch_pred).to('cpu'), batch_label.to('cpu'), topk=(1, 5))\n",
      "Evaluating Model...:   0%|          | 1/781 [00:01<17:37,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0 / 781]\tPrec@1 85.938 (85.938)\tPrec@5 93.750 (93.750)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  13%|█▎        | 101/781 [00:59<06:21,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100 / 781]\tPrec@1 75.572 (75.572)\tPrec@5 92.141 (92.141)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  26%|██▌       | 201/781 [01:56<05:43,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [200 / 781]\tPrec@1 75.218 (75.218)\tPrec@5 93.097 (93.097)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  39%|███▊      | 301/781 [02:53<04:39,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [300 / 781]\tPrec@1 75.851 (75.851)\tPrec@5 93.355 (93.355)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  51%|█████▏    | 401/781 [03:52<03:48,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [400 / 781]\tPrec@1 73.200 (73.200)\tPrec@5 91.619 (91.619)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  64%|██████▍   | 501/781 [05:01<02:57,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [500 / 781]\tPrec@1 71.551 (71.551)\tPrec@5 90.447 (90.447)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  77%|███████▋  | 601/781 [06:09<02:05,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [600 / 781]\tPrec@1 70.255 (70.255)\tPrec@5 89.588 (89.588)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  90%|████████▉ | 701/781 [08:25<02:09,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [700 / 781]\tPrec@1 69.307 (69.307)\tPrec@5 88.844 (88.844)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...: 100%|██████████| 781/781 [10:34<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 69.266 Prec@5 88.896\n"
     ]
    }
   ],
   "source": [
    "with ENABLE_CUDA_KERNEL():\n",
    "    model_builder, model_name  = torchvision.models.resnet18, 'resnet18'\n",
    "\n",
    "    print(f'---------------------- PPQ Quantization Test Running with {model_name} ----------------------')\n",
    "    model = model_builder(pretrained=True).to(CFG_DEVICE)\n",
    "\n",
    "    #测试FP32精度\n",
    "    # fp32_report = evaluate_torch_module_with_imagenet(\n",
    "    #     model=model, imagenet_validation_dir=CFG_VALIDATION_DIR,\n",
    "    #     batchsize=CFG_BATCHSIZE, device=CFG_DEVICE, verbose=True)\n",
    "\n",
    "    # 获取校准数据\n",
    "    dataloader = load_imagenet_from_directory(\n",
    "        directory=CFG_TRAIN_DIR, batchsize=CFG_BATCHSIZE,\n",
    "        shuffle=False, subset=5120, require_label=False,\n",
    "        num_of_workers=8)\n",
    "\n",
    "    # 量化torch模型\n",
    "    ppq_quant_ir = quantize_torch_model(\n",
    "        model=model, calib_dataloader=dataloader, input_shape=CFG_INPUT_SHAPE,\n",
    "        calib_steps=5120 // CFG_BATCHSIZE, collate_fn=lambda x: x.to(CFG_DEVICE), verbose=1,\n",
    "        device=CFG_DEVICE, platform=CFG_PLATFORM, setting=QUANT_SETTING,\n",
    "        onnx_export_file=f'{os.path.join(CFG_DUMP_PATH, model_name)}-FP32.onnx')\n",
    "        \n",
    "    # 评估PPQ量化后的模型\n",
    "    ppq_int8_report = evaluate_ppq_module_with_imagenet(\n",
    "        model=ppq_quant_ir, imagenet_validation_dir=CFG_VALIDATION_DIR,\n",
    "        batchsize=CFG_BATCHSIZE, device=CFG_DEVICE, verbose=True)\n",
    "\n",
    "    # 导出ORT模型\n",
    "    export_ppq_graph(\n",
    "        graph=ppq_quant_ir, \n",
    "        platform=TargetPlatform.ONNXRUNTIME,\n",
    "        graph_save_to=f'{os.path.join(CFG_DUMP_PATH, model_name)}-INT8.onnx')\n",
    "    \n",
    "    # 导出部署平台模型\n",
    "    export_ppq_graph(\n",
    "        graph=ppq_quant_ir, \n",
    "        platform=TargetPlatform.TRT_INT8,\n",
    "        graph_save_to=f'{os.path.join(CFG_DUMP_PATH, model_name)}-INT8.onnx')\n",
    "    \n",
    "    # 评估onnx运行模型\n",
    "    evaluate_onnx_module_with_imagenet(\n",
    "        onnxruntime_model_path=f'{os.path.join(CFG_DUMP_PATH, model_name)}-INT8.onnx', \n",
    "        imagenet_validation_dir=CFG_VALIDATION_DIR, batchsize=CFG_BATCHSIZE, \n",
    "        device=CFG_DEVICE)\n",
    "\n",
    "    # ppq_int8_report.to_csv(f'{os.path.join(CFG_DUMP_PATH, model_name)}-report.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估Openvino推理精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      ____  ____  __   ____                    __              __\n",
      "     / __ \\/ __ \\/ /  / __ \\__  ______ _____  / /_____  ____  / /\n",
      "    / /_/ / /_/ / /  / / / / / / / __ `/ __ \\/ __/ __ \\/ __ \\/ /\n",
      "   / ____/ ____/ /__/ /_/ / /_/ / /_/ / / / / /_/ /_/ / /_/ / /\n",
      "  /_/   /_/   /_____\\___\\_\\__,_/\\__,_/_/ /_/\\__/\\____/\\____/_/\n",
      "\n",
      "\n",
      "\u001b[31mTensorRT is not installed, TRT Exporter is disabled.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import openvino\n",
    "import openvino.runtime\n",
    "import cfg\n",
    "import torch\n",
    "from ppq.core import *\n",
    "from Utilities.Imagenet import evaluate_openvino_module_with_imagenet\n",
    "\n",
    "CFG_BATCHSIZE = 64                             # 测试与calib时的 batchsize\n",
    "CFG_INPUT_SHAPE = (CFG_BATCHSIZE, 3, 224, 224) # 用来确定模型输入的尺寸，好像 imagenet 都是这个尺寸\n",
    "CFG_VALIDATION_DIR = '/home/geng/tinyml/ppq/benchmark/Assets/Imagenet_Valid'   # 用来读取 validation dataset\n",
    "CFG_TRAIN_DIR = '/home/geng/tinyml/ppq/benchmark/Assets/Imagenet_Train'        # 用来读取 train dataset，注意该集合将被用来 calibrate 你的模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:   0%|          | 0/781 [00:00<?, ?it/s]/home/geng/tinyml/ppq/benchmark/classification/Utilities/Imagenet/imagenet_util.py:208: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prec1, prec5 = accuracy(torch.tensor(batch_pred).to('cpu'), batch_label.to('cpu'), topk=(1, 5))\n",
      "Evaluating Model...:   0%|          | 1/781 [00:01<13:10,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [0 / 781]\tPrec@1 81.250 (81.250)\tPrec@5 92.188 (92.188)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  13%|█▎        | 101/781 [00:32<03:33,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [100 / 781]\tPrec@1 74.165 (74.165)\tPrec@5 91.352 (91.352)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  26%|██▌       | 201/781 [01:03<03:02,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [200 / 781]\tPrec@1 73.298 (73.298)\tPrec@5 92.141 (92.141)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  39%|███▊      | 301/781 [01:35<02:29,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [300 / 781]\tPrec@1 73.785 (73.785)\tPrec@5 92.229 (92.229)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  51%|█████▏    | 401/781 [02:06<01:56,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [400 / 781]\tPrec@1 71.267 (71.267)\tPrec@5 90.290 (90.290)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  64%|██████▍   | 501/781 [02:37<01:27,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [500 / 781]\tPrec@1 69.586 (69.586)\tPrec@5 88.997 (88.997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  77%|███████▋  | 601/781 [03:08<00:55,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [600 / 781]\tPrec@1 68.274 (68.274)\tPrec@5 88.025 (88.025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...:  90%|████████▉ | 701/781 [03:39<00:24,  3.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: [700 / 781]\tPrec@1 67.196 (67.196)\tPrec@5 87.230 (87.230)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Model...: 100%|██████████| 781/781 [04:03<00:00,  3.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Prec@1 66.985 Prec@5 87.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>top1_accuracy</th>\n",
       "      <th>top5_accuracy</th>\n",
       "      <th>batch_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(0.8667)</td>\n",
       "      <td>81.2500</td>\n",
       "      <td>92.1875</td>\n",
       "      <td>0.397991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(0.6025)</td>\n",
       "      <td>82.8125</td>\n",
       "      <td>96.8750</td>\n",
       "      <td>0.346456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(1.0097)</td>\n",
       "      <td>71.8750</td>\n",
       "      <td>90.6250</td>\n",
       "      <td>0.325113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(0.7397)</td>\n",
       "      <td>81.2500</td>\n",
       "      <td>96.8750</td>\n",
       "      <td>0.313082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(1.3620)</td>\n",
       "      <td>70.3125</td>\n",
       "      <td>87.5000</td>\n",
       "      <td>0.301671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>tensor(0.4755)</td>\n",
       "      <td>87.5000</td>\n",
       "      <td>95.3125</td>\n",
       "      <td>0.263489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>tensor(0.7493)</td>\n",
       "      <td>85.9375</td>\n",
       "      <td>93.7500</td>\n",
       "      <td>0.264261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>tensor(0.6864)</td>\n",
       "      <td>81.2500</td>\n",
       "      <td>95.3125</td>\n",
       "      <td>0.262163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>tensor(1.8074)</td>\n",
       "      <td>53.1250</td>\n",
       "      <td>79.6875</td>\n",
       "      <td>0.263277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>tensor(2.9063)</td>\n",
       "      <td>34.3750</td>\n",
       "      <td>71.8750</td>\n",
       "      <td>0.259838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>781 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               loss  top1_accuracy  top5_accuracy  batch_time\n",
       "0    tensor(0.8667)        81.2500        92.1875    0.397991\n",
       "1    tensor(0.6025)        82.8125        96.8750    0.346456\n",
       "2    tensor(1.0097)        71.8750        90.6250    0.325113\n",
       "3    tensor(0.7397)        81.2500        96.8750    0.313082\n",
       "4    tensor(1.3620)        70.3125        87.5000    0.301671\n",
       "..              ...            ...            ...         ...\n",
       "776  tensor(0.4755)        87.5000        95.3125    0.263489\n",
       "777  tensor(0.7493)        85.9375        93.7500    0.264261\n",
       "778  tensor(0.6864)        81.2500        95.3125    0.262163\n",
       "779  tensor(1.8074)        53.1250        79.6875    0.263277\n",
       "780  tensor(2.9063)        34.3750        71.8750    0.259838\n",
       "\n",
       "[781 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openvino_executor = openvino.runtime.Core()\n",
    "name = 'ResNet18'\n",
    "target = \"OpenVino\"\n",
    "\n",
    "model_int8 = f'{os.path.join(cfg.OPENVINO_BASE_PATH, name)}-{target}-INT8.onnx'\n",
    "\n",
    "model_openvino = openvino_executor.compile_model(\n",
    "    model = openvino_executor.read_model(model=model_int8), device_name=\"CPU\")\n",
    "evaluate_openvino_module_with_imagenet(model=model_openvino,imagenet_validation_dir=CFG_VALIDATION_DIR,\n",
    "batchsize=CFG_BATCHSIZE,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "INPUT_SHAPE = (64, 3, 224, 224) # 用来确定模型输入的尺寸，好像 imagenet 都是这个尺寸\n",
    "SAMPLES = torch.rand(size=INPUT_SHAPE)\n",
    "res = torch.tensor(list(model_openvino([convert_any_to_numpy(SAMPLES)]).values())[0])   #openvino获取结推理果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0925,  0.9155,  1.4386,  ..., -1.0462,  0.1308,  2.4848],\n",
       "        [-1.7001,  0.7847,  1.5694,  ..., -0.9155,  0.0000,  2.2233],\n",
       "        [-1.7001,  0.6539,  1.1770,  ..., -0.9155,  0.1308,  2.2233],\n",
       "        ...,\n",
       "        [-1.5694,  0.6539,  1.3078,  ..., -0.7847,  0.1308,  2.6156],\n",
       "        [-1.7001,  0.7847,  1.4386,  ..., -0.7847,  0.0000,  2.6156],\n",
       "        [-2.0925,  0.5231,  1.1770,  ..., -0.9155,  0.2616,  2.4848]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(list(res)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ppq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1f49b93815805eca9ccc5299d655a62f3a8d0678e274dc3dfeb518f21176dcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
